== Deployment

Use Helm CLI to install Velero deployment and `restic` (_optional_).

=== {kube} cluster on-premise and _without_ backup persistent volume.

For the case that the external storage _supports_ volume snapshot natively and does not need Velero to backup the persistent volume data with `restic`.

==== Backup location on public cloud providers

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)

[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

Then, suggests to create at least one additional backup locations point to different object storage server to prevent object storage server single point of failure.

[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_NAME> \
    --config region=<REGION_NAME>
----

==== Backup location on S3-compatible storage providers

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, radosgw _or_ master/slave if you have HA S3 object storage backups)
. The S3-compatible object storage simulates the S3 object storage.

Therefore, the configuration for S3-compatible object storage have to setup additional configurations.

----
configuration.backupStorageLocation.config.s3ForcePathStyle=true
configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER__URL>
----

===== Setting the namespace for Velero installation _NAMESPACE_,. (optional)

The default namespace is `velero`.

[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
    --set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

Then, suggests to create at least one additional backup location point to different object storage server to prevent object storage server single point of failure.

[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_NAME> \
    --config region=slave,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----

=== {kube} cluster on-premise and _with_ backup persistent volume.

For the case that the external storage _not supports_ volume snapshot natively and need Velero to backup the persistent volume data by restic.

==== The backup location on public cloud providers

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)

[NOTE]
The public cloud provider supports persistent volume snapshot API. Therefore, we _do not have to_ deploy the `restic` DaemonSet.

[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=<REGION_NAME> \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

Then, suggest to create at least one additional backup locations point to different object storage server to prevent object storage server single point of failure.

[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_NAME> \
    --config region=<REGION_NAME>
----

==== Backup location on S3-compatible storage providers

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, radosgw _or_ master/slave if you have HA S3 object storage backups)
. The S3-compatible object storage simulates the S3 object storage.

Therefore, the configuration for S3-compatible object storage have to setup additional configurations

----
configuration.backupStorageLocation.config.s3ForcePathStyle=true
configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER__URL>
----

===== Setting the namespace for Velero installation _NAMESPACE_,. (optional)

The default namespace is `velero`.

[NOTE]
Mostly the on-premise persistent volume does not supports snapshot API or does not have community supportded snapshotter providers (for example, the NFS volume does not supports the snapshot API). Therefore, we _have to_ deploy the `restic` DaemonSet.

[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
    --set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=minio \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

Then, suggest to create at least one additional backup locations point to different object storage server to prevent object storage server single point of failure.

[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_NAME> \
    --config region=slave,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----

[NOTE]
For troubleshooting a velero deployment, refer to: link:https://velero.io/docs/v1.2.0/debugging-install/[Velero: Debugging Installation Issues]
