[[rbac]]
= Role Based Access Control (RBAC)

== Introduction

RBAC uses the `rbac.authorization.k8s.io` API group to drive authorization decisions, allowing administrators to dynamically configure policies through the {kube} API.

The authentication components are deployed as part of the {productname} installation.
Administrators can update LDAP identity providers before or after platform deployment.
After deploying {productname}, administrators can use {kube} RBAC to design
user or group authorizations.
Users can access with a Web browser or command line to do the authentication and
self-configure `kubectl` to access authorized resources.

== Authentication Flow

Authentication is composed of:

* *Dex* (https://github.com/dexidp/dex) is an identity provider service
(idP) that uses OIDC (Open ID Connect: https://openid.net/connect/)
to drive authentication for client applications.
It acts as a portal to defer authentication to provider through connected
identity providers (connectors).
* *Client*:
  . Web browser: *Gangway* (https://github.com/heptiolabs/gangway):
  a Web application that enables authentication flow for your {productname}.
  The user can login, authorize access, download `kubeconfig` or self-configure `kubectl`.
  . Command line: `skuba auth login`, a CLI application that enables authentication
  flow for your {productname}. The user can log in, authorize access, and get `kubeconfig`.

For RBAC, administrators can use `kubectl` to create corresponding
`RoleBinding` or `ClusterRoleBinding` for a user or group to limit resource access.

=== Web Flow
image::oidc_flow_web.png[]
// Source: suse-rbac-oidc-flow-web.xml (open with http://draw.io/app)

. User requests access through Gangway.
. Gangway redirects to Dex.
. Dex redirects to connected identity provider (connector).
User login and a request to approve access are generated.
. Dex continues with OIDC authentication flow on behalf of the user
and creates/updates data to {kube} CRDs.
. Dex redirects the user to Gangway.
This redirect includes (ID/refresh) tokens.
. Gangway returns a link to download `kubeconfig` or self-configures `kubectl`
instructions to the user.
+
image::rbac-configure-kubectl.png[]

. User downloads `kubeconf` or self-configures `kubectl`.
. User uses `kubectl` to connect to the {kube} API server.
. {kube} CRDs validate the {kube} API server request and return a response.
. The `kubectl` connects to the authorized {kube} resources through the {kube} API server.

=== CLI Flow
image::oidc_flow_cli.png[]
// Source: suse-rbac-oidc-flow-cli.xml (open with http://draw.io/app)

. User requests access through `skuba auth login` with the Dex server URL,
username and password.
. Dex uses received username and password to log in and approve the access
request to the connected identity providers (connectors).
. Dex continues with the OIDC authentication flow on behalf of the user and
creates/updates data to the {kube} CRDs.
. Dex returns the ID token and refresh token to `skuba auth login`.
. `skuba auth login` generates the kubeconfig file `kubeconf.txt`.
. User uses `kubectl` to connect the {kube} API server.
. {kube} CRDs validate the {kube} API server request and return a response.
. The `kubectl` connects to the authorized {kube} resources through {kube} API server.

== RBAC Operations

=== Administration

==== {kube} Role Binding

Administrators can create {kube} `RoleBinding` or `ClusterRoleBinding` for users.
This grants permission to users on the {kube} cluster like in the example below.

In order to create a `RoleBinding` for `<USER_1>`, `<USER_2>`, and `<GROUP_1>`
using the `ClusterRole` `admin` you would run the following:

[source,bash]
----
kubectl create rolebinding admin --clusterrole=admin --user=<USER_1> --user=<USER_2> --group=<GROUP_1>
----

[[_sec.admin.security.rbac.update]]
==== Update the Authentication Connector

[IMPORTANT]
====
Before any add-on upgrade, please backup any runtime configuration changes, then restore the modification back after upgraded.
It is a known limitation of the addon customization process.
====

Administrators can update the authentication connector settings after {productname}
deployment as follows:

. Based on the manifest in `my-cluster/addons/dex/base/dex.yaml`, provide a kustomize patch to `my-cluster/addons/dex/patches/dex-patch.yaml` of the form of strategic merge patch or a JSON 6902 patch.
+
Read https://github.com/kubernetes-sigs/kustomize/blob/master/docs/glossary.md#patchstrategicmerge and https://github.com/kubernetes-sigs/kustomize/blob/master/docs/glossary.md#patchjson6902 to get more information.
+
. Adapt ConfigMap by adding LDAP configuration to the connector section.
For detailed configuration of the LDAP connector, refer to the Dex documentation:
https://github.com/dexidp/dex/blob/v2.16.0/Documentation/connectors/ldap.md.
The following is an *example LDAP connector:*
+
[source,yaml]
----
  connectors:
  - type: ldap
    id: 389ds
    name: 389ds
    config:
      host: ldap.example.org:636
      rootCAData: <base64 encoded PEM file>
      bindDN: cn=Directory Manager
      bindPW: <Password of Bind DN>
      usernamePrompt: Email Address
      userSearch:
        baseDN: ou=Users,dc=example,dc=org
        filter: "(objectClass=person)"
        username: mail
        idAttr: DN
        emailAttr: mail
        nameAttr: cn
      groupSearch:
        baseDN: ou=Groups,dc=example,dc=org
        filter: "(objectClass=groupOfNames)"
        userAttr: uid
        groupAttr: memberUid
        nameAttr: cn
----
. A base64 encoded PEM file can be generated by running:
+
[source,bash]
----
cat <ROOT_CA_PEM_FILE> | base64 | awk '{print}' ORS='' && echo
----
+
Besides the LDAP connector you can also set up other connectors.
For additional connectors, refer to the available connector configurations in the Dex repository:
https://github.com/dexidp/dex/tree/v2.16.0/Documentation/connectors.
. Create a `kustomization.yaml` file in `my-cluster/addons/dex/kustomization.yaml`
+
[source,yaml]
----
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - base/dex.yaml
patches:
  - patches/dex-patch.yaml
----
. Apply the changes with:
+
----
kubectl apply -k my-cluster/addons/dex/
----

[[_sec.admin.security.rbac.apply]]
=== User Access

==== Setting up `kubectl`

===== In the Web Browser

. Go to the login page at `+https://<CONTROL_PLANE_IP/FQDN>:32001+` in your browser.
. Click "Sign In".
. Choose the login method.
. Enter the login credentials.
. Download `kubeconfig` or self-configure `kubectl` with the provided setup instructions.

===== Using the CLI

. Use `skuba auth login` with Dex server URL `+https://<CONTROL_PLANE_IP/FQDN>:32000+`,
login username and password.
. The kubeconfig `kubeconf.txt` is generated locally.

===== OIDC Tokens

The kubeconfig file (`kubeconf.txt`) contains the OIDC tokens necessary to perform authentication and authorization in the cluster.
OIDC tokens have an *expiration date* which means that they need to be refreshed after some time.

[IMPORTANT]
====
If you use the same user in multiple `kubeconfig` files distributed among multiple machines,
this can lead to issues. Due to the nature off access and refresh tokens (https://tools.ietf.org/html/rfc6749#page-10) only one of the machines will be fully able to refresh the token set at any given time.

The user will be able to download multiple `kubeconfig` files, but they will only work until one of them needs to refresh the session.
After that, only one machine will work, namely the first machine which refreshed the token.

Dex regards one session per user and refreshes `id-token` and `refresh-token` together.
If there is a second user trying to login to get a new `id-token`, Dex will invalidate the previous `id-token` and `refresh-token` for the first user.
The first user will still be able to use the old `id-token` until expiration but after that the first user is not allowed to refresh the `id-token` with the now invalid `refresh-token`.
Only the second user will have a valid `refresh-token`. You will encounter an error like: `"msg="failed to rotate keys: keys already rotated by another server instance"`.

If sharing the same `id-token` in many places, all of them can be used until expiration.
The first user refreshing the `id-token` & `refresh token` will be able to continue accessing the cluster until the tokens expire.
All other users will encounter an error `Refresh token is invalid or has already been claimed by another client` because the `refresh-token` got updated by the first user.

Please use separate users for each `kubeconfig` file to avoid this situation.
Find out how to add more users in <<_sec.admin.security.users.add>>.
You can also check information about the user and the respective OIDC tokens in the `kubeconfig` file under the `users` section:

----
users:
- name: myuser
  user:
    auth-provider:
      config:
        client-id: oidc
        client-secret: <SECRET>
        id-token:  <ID_TOKEN>
        idp-issuer-url: https://<IP>:<PORT>
        refresh-token: <REFRESH_TOKEN>
      name: oidc
----
====

==== Access {kube} Resources

The user can now access resources in the authorized `<NAMESPACE>`.

If the user has the proper permissions to access the resources, the output should look like this:

----
# kubectl -n <NAMESPACE> get pod

NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE
kube-system   dex-844dc9b8bb-w2zkm                 1/1     Running   0          19d
kube-system   gangway-944dc9b8cb-w2zkm             1/1     Running   0          19d
kube-system   cilium-76glw                         1/1     Running   0          27d
kube-system   cilium-fvgcv                         1/1     Running   0          27d
kube-system   cilium-j5lpx                         1/1     Running   0          27d
kube-system   cilium-operator-5d9cc4fbb7-g5plc     1/1     Running   0          34d
kube-system   cilium-vjf6p                         1/1     Running   8          27d
kube-system   coredns-559fbd6bb4-2r982             1/1     Running   9          46d
kube-system   coredns-559fbd6bb4-89k2j             1/1     Running   9          46d
kube-system   etcd-my-master                       1/1     Running   5          46d
kube-system   kube-apiserver-my-cluster            1/1     Running   0          19d
kube-system   kube-controller-manager-my-master    1/1     Running   14         46d
kube-system   kube-proxy-62hls                     1/1     Running   4          46d
kube-system   kube-proxy-fhswj                     1/1     Running   0          46d
kube-system   kube-proxy-r4h42                     1/1     Running   1          39d
kube-system   kube-proxy-xsdf4                     1/1     Running   0          39d
kube-system   kube-scheduler-my-master             1/1     Running   13         46d
----

If the user does not have the right permissions to access a resource,
they will receive a `Forbidden` message.

----
Error from server (Forbidden): pods is forbidden
----
