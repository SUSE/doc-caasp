== Deployment

Use Helm CLI to install Velero deployment and `restic` (_optional_) if the storage does not provide volume snapshot API.

[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

[NOTE]
====
For troubleshooting a velero deployment, refer to link:https://velero.io/docs/v1.4/debugging-install/[Velero: Debugging Installation Issues]
====

=== Backup {kube} Cluster Objects Only

For the cases that the {kube} cluster do not use external storage _or_ the external storage would handle take volume snapshot by itself, it does not need Velero to backup persistent volume.

* Backup To A Public Cloud Provider

** Amazon Web Services (AWS)
. The backup bucket name _BUCKET_NAME_. (The bucket name in AWS S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the AWS S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-aws:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=aws \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --region=<REGION_NAME>
----

** Google Cloud Platform (GCP)
. The backup bucket name _BUCKET_NAME_. (The bucket name in Google Cloud Storage object storage)
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=gcp \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-gcp \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-gcp:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=gcp \
    --bucket=<SECONDARY_BUCKET_NAME>
----

** Microsoft Azure
. The backup bucket name _BUCKET_NAME_. (The bucket name in Azure Blob Storage	 object storage)
. The resource group name __AZURE_RESOURCE_GROUP__. (The Azure resource group name)
. The storage account ID __AZURE_STORAGE_ACCOUNT_ID__. (The Azure storage account ID)
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=azure \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.resourceGroup=<AZURE_RESOURCE_GROUP> \
    --set configuration.backupStorageLocation.config.storageAccount=<AZURE_STORAGE_ACCOUNT_ID> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-microsoft-azure \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-microsoft-azure:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=azure \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --region resourceGroup=<AZURE_RESOURCE_GROUP>,storageAccount=<AZURE_STORAGE_ACCOUNT_ID>
----

* Backup To A S3-Compatible Provider

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3-compatible object storage)
. The backup region name _REGION_NAME_. (The region name for the S3-compatible object storage. For example, radosgw _or_ default/secondary if you have an HA backup servers)
. The S3-compatible object storage simulates the S3-compatible object storage. Therefore, the configuration for S3-compatible object storage have to setup additional configurations.
+
[source,bash]
----
--set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
--set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
----
. If the S3-Compatible storage server is secured with a self-signed certificate, add the below command when helm install and pass `--cacert` flag when using Velero CLI, refer to link:https://velero.io/docs/v1.4/self-signed-certificates/[Velero: Self Signed Certificates]. (optional)
+
[source,bash]
----
--set configuration.backupStorageLocation.caCert=`cat <PATH_TO_THE_SELF_SIGNED_CA_CERTIFICATE> | base64 -w 0 && echo` \
----
. Install Velero Deployment.
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
    --set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-aws:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup location point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=aws \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --config region=secondary,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----

=== Backup {kube} Cluster

For the case that the {kube} cluster uses external storage _and_ the external storage would not handle volume snapshot by itself (either external storage does not support volume snapshot _or_ administrator want use velero to take volume snapshot when velero do cluster backup).

* Backup To A Public Cloud Provider

** Amazon Web Services (AWS)
. The backup bucket name _BUCKET_NAME_. (The bucket name in AWS S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the AWS S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[IMPORTANT]
====
If the {kube} cluster in AWS and uses AWS EBS as storage, please remove the
----
--set deployRestic=true \
----
at below to use AWS EBS volume snapshot API to take volume snapshot.
Otherwise, it would install restic and velero server will use restic to take a volume snapshot and the volume data will store to AWS S3 bucket.
====
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=<REGION_NAME> \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-aws:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=aws \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --config region=<REGION_NAME>
----

** Google Cloud Platform (GCP)
. The backup bucket name _BUCKET_NAME_. (The bucket name in Google Cloud Storage object storage)
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
// TODO: enable this once skuba supports deploys on GCP
// +
// [IMPORTANT]
// ====
// If the {kube} cluster in GCP and uses Google Compute Engine Disks as storage, please remove the
// ----
// --set deployRestic=true \
// ----
// at below in order to use Google Compute Engine Disks snapshot API to take volume snapshot.
// Otherwise, it would install restic and velero server will use restic to take volume snapshot and the volume data will stores to  Google Cloud Storage bucket.
// ====
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=gcp \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set initContainers[0].name=velero-plugin-for-gcp \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-gcp:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=gcp \
    --bucket=<SECONDARY_BUCKET_NAME>
----

** Microsoft Azure
. The backup bucket name _BUCKET_NAME_. (The bucket name in Azure Blob Storage object storage)
. The resource group name __AZURE_RESOURCE_GROUP__. (The Azure resource group name)
. The storage account ID __AZURE_STORAGE_ACCOUNT_ID__. (The Azure storage account ID)
. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
// TODO: enable this once skuba supports deploys on Azure
// +
// [IMPORTANT]
// ====
// If the {kube} cluster in Azure and uses Azure Managed Disks as storage, please remove the
// ----
// --set deployRestic=true \
// ----
// at below in order to use Azure Managed Disks snapshot API to take volume snapshot.
// Otherwise, it would install restic and velero server will use restic to take volume snapshot and the volume data will stores to Azure Blob Storage bucket.
// ====
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=azure \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.resourceGroup=<AZURE_RESOURCE_GROUP> \
    --set configuration.backupStorageLocation.config.storageAccount=<AZURE_STORAGE_ACCOUNT_ID> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set initContainers[0].name=velero-plugin-for-microsoft-azure \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-microsoft-azure:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=azure \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --region resourceGroup=<AZURE_RESOURCE_GROUP>,storageAccount=<AZURE_STORAGE_ACCOUNT_ID>
----

* Backup To A S3-Compatible Provider

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3-compatible object storage)
. The backup region name _REGION_NAME_. (The region name for the S3-compatible object storage. For example, radosgw _or_ default/secondary if you have an HA backup servers)
. The S3-compatible object storage simulates the S3-compatible object storage. Therefore, the configuration for S3-compatible object storage have to setup additional configurations.
+
[source,bash]
----
--set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
--set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
----
. If the S3-Compatible storage server is secured with a self-signed certificate, add the below command when helm install and pass `--cacert` flag when using Velero CLI, refer to link:https://velero.io/docs/v1.4/self-signed-certificates/[Velero: Self Signed Certificates]. (optional)
+
[source,bash]
----
--set configuration.backupStorageLocation.caCert=`cat <PATH_TO_THE_SELF_SIGNED_CA_CERTIFICATE> | base64 -w 0 && echo` \
----
. Install Velero Deployment and restic DaemonSet.
+
[NOTE]
====
Mostly the on-premise persistent volume does not support volume snapshot API or does not have community-supported snapshotter providers. Therefore, we _have to_ deploy the `restic` DaemonSet.
====
+
[source,bash]
----
helm install velero \
    --namespace=<NAMESPACE> \
    --create-namespace \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.bucket=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
    --set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=minio \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4.5/velero-plugin-for-aws:1.1.0 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----

. Then, suggest creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create secondary \
    --provider=aws \
    --bucket=<SECONDARY_BUCKET_NAME> \
    --config region=secondary,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----
