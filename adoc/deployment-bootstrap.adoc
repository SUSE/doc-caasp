== Bootstrapping the cluster

=== Preparation

==== Install caaspctl

First you need to install caaspctl on your local workstation:

. Add the SLE15 SP1 repository containing caaspctl.
+
----
sudo zypper ar http://download.suse.de/ibs/SUSE:/SLE-15-SP1:/Update:/Products:/CASP40/standard/ caasp_vnext
----
. Install caaspctl:
+
----
sudo zypper in caaspctl
----

=== Cluster Deployment

Make sure you have added the SSH identity (corresponding to the SSH key distributed above) to the ssh-agent on your workstation. This is a requirement for caaspctl (https://github.com/SUSE/caaspctl#prerequisites).

[TIP]
====
The `ssh-agent` process is usually started automatically by most UNIX
environments. If that's not the case, invoke the `ssh-agent` command
and follow the guidance given by the tool's output.

You can load as many keys as you want into your agent using the
`ssh-add <path to key>` command. Keys can also be password protected.

You can list all the identities loaded into the agent by using the
`ssh-add -L` command.

caaspctl will try all the identities loaded into the ssh-agent until one of
them grants access to the node.

It is also possible to forward the authentication agent connection from a
host to another one. This can be useful if you intend to run caaspctl on
a "jump host" and don't want to copy your private key to this node.

This can be achieved using the `ssh -A` command. Please refer to the man page
of ssh to learn about the security implications of using this feature.
====


Now you can initialize the cluster on the deployed machines.
As `--control-plane` enter the IP/FQDN of your load balancer. If you do not use a load balancer use your first master node.
+
----
caaspctl cluster init --control-plane <LB IP/FQDN> my-cluster
----
`cluster init` generates the folder named `my-cluster` and initializes the directory that will hold the configuration for the cluster.
. Switch to the new directory.
. Now bootstrap a master node.
For `--target` enter the IP address of your first master node.
Replace `<NODE NAME>` with a unique identifier for example "master-one".
+
[WARNING]
====
The directory created during this step contains configuration files that allow full administrator access to your cluster. Apply best practices for access control to this folder.
====
+
----
cd my-cluster
caaspctl node bootstrap  --user sles --sudo --target <IP/FQDN> <NODE NAME>
----
This will bootstrap the specified node as the first master in the cluster.
The process will generate authentication certificates and the `admin.conf` file that is used for authentication against the cluster.
The files will be stored in the `my-cluster` directory specified in step one.
. Add additional master nodes to the cluster.
+
Replace the `<IP/FQDN>` with the IP for the machine.
Replace `<NODE NAME>` with a unique identifier for example "master-two".
+
----
caaspctl node join --role master --user sles --sudo --target <IP/FQDN> <NODE NAME>
----
. Add a worker to the cluster.
+
Replace the `<IP/FQDN>` with the IP for the machine.
Replace `<NODE NAME>` with a unique identifier for example "worker-one".
+
----
caaspctl node join --role worker --user sles --sudo --target <IP/FQDN> <NODE NAME>
----
. Verify the nodes that you added
+
----
caaspctl cluster status
----
+
The output should look like this:
+
----
NAME         OS-IMAGE                              KERNEL-VERSION        CONTAINER-RUNTIME   HAS-UPDATES   HAS-DISRUPTIVE-UPDATES
master-one   SUSE Linux Enterprise Server 15 SP1   4.12.14-110-default   cri-o://1.13.3      <none>        <none>
worker-one   SUSE Linux Enterprise Server 15 SP1   4.12.14-110-default   cri-o://1.13.3      <none>        <none>
----

=== Using kubectl

You can install and use kubectl by installing the kubernetes-client package from  http://download.suse.de/ibs/SUSE:/SLE-15-SP1:/Update:/Products:/CASP40/standard/.

[TIP]
====
Alternatively you can install from upstream: https://kubernetes.io/docs/tasks/tools/install-kubectl/.
====

To talk to your cluster, simply symlink the generated configuration file to `~/.kube/config`.

[source,bash]
----
ln -s ~/clusters/my-cluster/admin.conf ~/.kube/config
----

Then you can perform all cluster operations as usual. For example checking cluster status with either:

* `kubectl get nodes -o wide`
+
or
* `kubectl caasp cluster status`
+
or
* `kubectl get pods --all-namespaces`
+
[source,bash]
----
# kubectl get pods --all-namespaces

NAMESPACE     NAME                                READY     STATUS    RESTARTS   AGE
kube-system   coredns-86c58d9df4-5zftb            1/1       Running   0          2m
kube-system   coredns-86c58d9df4-fct4m            1/1       Running   0          2m
kube-system   etcd-my-master                      1/1       Running   0          1m
kube-system   kube-apiserver-my-master            1/1       Running   0          1m
kube-system   kube-controller-manager-my-master   1/1       Running   0          1m
kube-system   kube-flannel-ds-amd64-b6krs         1/1       Running   0          53s
kube-system   kube-flannel-ds-amd64-v7kt7         1/1       Running   0          2m
kube-system   kube-proxy-5qxnt                    1/1       Running   0          2m
kube-system   kube-proxy-746ws                    1/1       Running   0          53s
kube-system   kube-scheduler-my-master            1/1       Running   0          1m
----
