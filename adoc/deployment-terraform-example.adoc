== Terraform Config Examples

[[tf.default]]
=== Terraform Default Configuration
# tag::tf_openstack[]
[source,json]
----
# Name of the image to use
image_name = "SLE-15-SP1-JeOS-GMC"

# Identifier to make all your resources unique and avoid clashes with other users of this Terraform project
stack_name = "testing" // <1>

# Name of the internal network to be created
internal_net = "testing-net" // <2>

# Name of the internal subnet to be created
# IMPORTANT: If this variable is not set or empty,
# then it will be generated following a schema like
# internal_subnet = "${var.internal_net}-subnet"
internal_subnet = "testing-subnet"

# Name of the internal router to be created
# IMPORTANT: If this variable is not set or empty,
# then it will be generated following a schema like
# internal_router = "${var.internal_net}-router"
internal_router = "testing-router"

# Name of the external network to be used, the one used to allocate floating IPs
external_net = "floating"

# CIDR of the subnet for the internal network
subnet_cidr = "172.28.0.0/24"

# Number of master nodes
masters = 3 // <3>

# Number of worker nodes
workers = 2 // <4>

# Size of the master nodes
master_size = "t2.large"

# Size of the worker nodes
worker_size = "t2.large"

# Attach persistent volumes to workers
workers_vol_enabled = 0

# Size of the worker volumes in GB
workers_vol_size = 5

# Name of DNS domain
dnsdomain = "testing.example.com"

# Set DNS Entry (0 is false, 1 is true)
dnsentry = 0

# Optional: Define the repositories to use
# repositories = {
#   repository1 = "http://repo.example.com/repository1/"
#   repository2 = "http://repo.example.com/repository2/"
# }
repositories = {} // <5>

# Define required packages to be installed/removed. Do not change those.
packages = [  // <6>
  "kernel-default",
  "-kernel-default-base",
  "new-package-to-install"
]

# ssh keys to inject into all the nodes
authorized_keys = [ // <7>
  ""
]

# IMPORTANT: Replace these ntp servers with ones from your infrastructure
ntp_servers = ["0.example.ntp.org", "1.example.ntp.org", "2.example.ntp.org", "3.example.ntp.org"] // <8>

----
<1> `stack_name`: Prefix for all machines of the cluster spawned by terraform.
<2> `internal_net`: the internal network name that will be created/used for the cluster in {soc}.
*Note*: This string will be used to generate the human readable IDs in {soc}.
If you use a generic term, deployment is very likely to fail because the term is already in use by someone else. It's a good idea to use your username or some other unique identifier.
<3> `masters`: Number of master nodes to be deployed.
<4> `workers`: Number of worker nodes to be deployed.
<5> `repositories`: A list of additional repositories to be added on each
machines. Leave empty if no additional packages need to be installed.
<6> `packages`: Additional packages to be installed on the node.
*Note*: Do not remove any of the pre-filled values in the `packages` section. This can render
your cluster unusable. You can add more packages but do not remove any of the
default packages listed.
<7> `authorized_keys`: List of ssh public keys that will be injected into the
cluster nodes, allowing you to be able to log in into them via SSH as `sles`
user.  Copy and paste the text from the _keyname_.pub file here, *not* the
private key.  At least one of the keys must match a key loaded into your
`ssh-agent`.
<8> `ntp_servers`: A list of `ntp` servers you would like to use with `chrony`.
# end::tf_openstack[]

[[tf.vmware]]
=== Terraform VMware Configuration
# tag::tf_vmware[]
[source,json]
----
# datastore to use in vSphere
vsphere_datastore = "STORAGE-0" // <1>

# datastore_ cluster to use in vSphere
vsphere_datastore_cluster = "STORAGE-CLUSTER-0" // <2>

# datacenter to use in vSphere
vsphere_datacenter = "DATACENTER" // <3>

# network to use in vSphere
vsphere_network = "VM Network" // <4>

# resource pool the machines will be running in
vsphere_resource_pool = "esxi1/Resources" // <5>

# template name the machines will be copied from
template_name = "sles15-sp2-caasp" // <6>

# IMPORTANT: Replace by "efi" string in case your template was created by using EFI firmware
firmware = "bios"

# prefix that all of the booted machines will use
# IMPORTANT: please enter unique identifier below as value of
# stack_name variable to not interfere with other deployments
stack_name = "caasp-v5" // <7>

# Number of master nodes
masters = 1 // <8>

# Optional: Size of the root disk in GB on master node
master_disk_size = 50 // <9>

# Number of worker nodes
workers = 2 // <10>

# Optional: Size of the root disk in GB on worker node
worker_disk_size = 40 // <11>

# Username for the cluster nodes. Must exist on base OS.
username = "sles" // <12>

# Optional: Define the repositories to use
# repositories = {
#   repository1 = "http://repo.example.com/repository1/"
#   repository2 = "http://repo.example.com/repository2/"
# }
repositories = {} // <13>

# Minimum required packages. Do not remove them.
# Feel free to add more packages
packages = [ // <14>
]

# ssh keys to inject into all the nodes
authorized_keys = [ // <15>
  "ssh-rsa <example_key> example@example.com"
]

# IMPORTANT: Replace these ntp servers with ones from your infrastructure
ntp_servers = ["0.example.ntp.org", "1.example.ntp.org", "2.example.ntp.org", "3.example.ntp.org"] // <16>
----

[IMPORTANT]
====
Only one of `vsphere_datastore` or `vsphere_datastore_cluster` can be set at the same time. Proceed to comment or delete the unused one from your `terraform.tfvars`
====

<1> `vsphere_datastore`: The datastore to use. This option is mutually exclusive with `vsphere_datastore_cluster`.
<2> `vsphere_datastore_cluster`: The datastore cluster to use. This option is mutually exclusive with `vsphere_datastore`.
<3> `vsphere_datacenter`: The datacenter to use.
<4> `vsphere_network`: The network to use.
<5> `vsphere_resource_pool`: The root resource pool or an user-created child resource pool. Refer to https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.resmgmt.doc/GUID-60077B40-66FF-4625-934A-641703ED7601.html for detailed information.
<6> `template_name`: The name of the template created according to instructions.
<7> `stack_name`: Prefix for all machines of the cluster spawned by terraform.
*Note*: This string will be used to generate the human readable IDs in {soc}.
If you use a generic term, deployment very likely to fail because the term is already in use by someone else. It's a good idea to use your username or some other unique identifier.
<8> `masters`: Number of master nodes to be deployed.
<9> `master_disk_size`: Size of the root disk in GB.
*Note*: The value must be at least the same size as the source template. It is only possible to increase the size of a disk.
<10> `workers`: Number of worker nodes to be deployed.
<11> `worker_disk_size`: Size of the root disk in GB.
*Note*: The value must be at least the same size as the source template. It is only possible to increase the size of a disk.
<12> `username`: Login username for the nodes.
*Note*: Leave this as the default `sles`. The username must exist on the used base operating system. It will not be created.
<13> `repositories`: A list of additional repositories to be added on each
machines. Leave empty if no additional packages need to be installed.
<14> `packages`: Additional packages to be installed on the node.
*Note*: Do not remove any of the pre-filled values in the `packages` section. This can render
your cluster unusable. You can add more packages but do not remove any of the
default packages listed.
<15> `authorized_keys`: List of ssh-public-keys that will be able to log in to the
deployed machines.
<16> `ntp_servers`: A list of `ntp` servers you would like to use with `chrony`.
# end::tf_vmware[]


[[tf.aws]]
=== Terraform AWS Configuration
# tag::tf_aws[]
[source,json]
----
# prefix that all of the booted machines will use
# IMPORTANT, please enter unique identifier below as value of
# stack_name variable to not interfere with other deployments
stack_name = "caasp-v5" // <1>

# AWS region
aws_region = "eu-central-1"  // <2>

# AWS availability zone
aws_az = "eu-central-1a" // <3>

# access key for AWS services
aws_access_key = "AKIXU..."  // <4>

# secret key used for AWS services
aws_secret_key = "ORd..." // <5>

# Number of master nodes
masters = 1 // <6>

# Number of worker nodes
workers = 2 // <7>

# ssh keys to inject into all the nodes
# EXAMPLE:
# authorized_keys = [
#   "ssh-rsa <key-content>"
# ]
authorized_keys = [ // <8>
  "ssh-rsa <example_key> example@example.com"
]

# To register CaaSP product please use ONLY ONE of the following method
#
# SUSE CaaSP Product Product Key:
#caasp_registry_code = ""  // <9>
#
# SUSE Repository Mirroring Server Name (FQDN):
#rmt_server_name = "rmt.example.com"  // <10>

# List of VPC IDs to join via VPC peer link
#peer_vpc_ids = ["vpc-id1", "vpc-id2"] // <11>

# Name of the IAM profile to associate to control plane nodes
# Leave empty to have terraform create one.
# This is required to have AWS CPI support working properly.
#
# Note well: you must  have the right set of permissions.
# iam_profile_master = "caasp-k8s-master-vm-profile" // <12>

# Name of the IAM profile to associate to worker nodes.
# Leave empty to have terraform create one.
# This is required to have AWS CPI support working properly.
#
# Note well: you must  have the right set of permissions.
#iam_profile_worker = "caasp-k8s-worker-vm-profile" // <13>
----
<1> `stack_name`: Prefix for all machines of the cluster spawned by terraform.
<2> `aws_region`: The region in AWS.
<3> `aws_az`: The availability zone in AWS.
<4> `aws_access_key`: AWS access key.
<5> `aws_secrert_key`: AWS secret key.
<6> `masters`: Number of master nodes to be deployed.
<7> `workers`: Number of worker nodes to be deployed.
<8> `authorized_keys`: List of ssh-public-keys that will be able to log into
the deployed machines.
<9> `caasp_registry_code`: {productname} Product Key for registering
the product against {scc}.
<10> `caasp_registry_code`: register against a local SUSE Repository
Mirroring Server.
<11> `peer_vpc_ids`: List of already existing VPCs to join via dedicated VPC
peering links.
<12> `iam_profile_master`: Name of the IAM profile to associate with the control
plane instance. Leave empty to have {tf} create it.
<13> `iam_profile_worker`: Name of the IAM profile to associate with the worker
instances. Leave empty to have {tf} create it.

# end::tf_aws[]
