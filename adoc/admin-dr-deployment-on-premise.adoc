== Deployment On On-Premise

Use Helm CLI to install Velero deployment and `restic` (_optional_).

=== {kube} cluster on on-premise and _without_ backup persistent volume.

For the following either cases:

1. the {kube} cluster does not use external storage.
2. the external storage would handle take volume snapshot by itself, it does not need Velero to backup persistent volume.

==== The backup location on public cloud providers.

. AWS
.. The backup bucket name _BUCKET_NAME_. (The bucket name in AWS S3 object storage)
.. The backup region name _REGION_NAME_. (The region name for the AWS S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

.. Then, suggests creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_SLAVE_NAME> \
    --region <REGION_NAME>
----

. GCP
.. The backup bucket name _BUCKET_NAME_. (The bucket name in Google Cloud Storage object storage)
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=gcp \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-gcp \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-gcp:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

.. Then, suggests creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider gcp \
    --bucket <BUCKET_SLAVE_NAME>
----

. Azure
.. The backup bucket name _BUCKET_NAME_. (The bucket name in Azure Blob Storage	 object storage)
.. The resource group name __AZURE_RESOURCE_GROUP__. (The Azure resource group name)
.. The storage account ID __AZURE_STORAGE_ACCOUNT_ID__. (The Azure storage account ID)
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=azure \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.resourceGroup=<AZURE_RESOURCE_GROUP> \
	--set configuration.backupStorageLocation.config.storageAccount=<AZURE_STORAGE_ACCOUNT_ID> \
    --set snapshotsEnabled=false \
    --set initContainers[0].name=velero-plugin-for-microsoft-azure \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-microsoft-azure:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

.. Then, suggests creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider azure \
    --bucket <BUCKET_SLAVE_NAME> \
    --region resourceGroup=<AZURE_RESOURCE_GROUP>,storageAccount=<AZURE_STORAGE_ACCOUNT_ID>
----

==== The backup location on S3-compatible storage providers.

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, radosgw _or_ master/slave if you have HA S3 object storage backups)
. The S3-compatible object storage simulates the S3 object storage. Therefore, the configuration for S3-compatible object storage has to setup additional configurations.
+
[source,bash]
----
configuration.backupStorageLocation.config.s3ForcePathStyle=true
configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER__URL>
----
. Then, suggests creating at least one additional backup location point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_SLAVE_NAME> \
    --config region=slave,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----

=== {kube} cluster on on-premise and _with_ backup persistent volume.

For the case that the {kube} cluster uses external storage _and_ the external storage would not handle volume snapshot by itself (either external storage does not support volume snapshot _or_ administrator want use velero to take volume snapshot when velero do cluster backup).

==== The backup location on public cloud providers.

. AWS
.. The backup bucket name _BUCKET_NAME_. (The bucket name in AWS S3 object storage)
.. The backup region name _REGION_NAME_. (The region name for the AWS S3 object storage. For example, `us-east-1` for AWS US East (N. Virginia))
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=<REGION_NAME> \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

..  Then, suggest to create at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_SLAVE_NAME> \
    --config region=<REGION_NAME>
----

. GCP
.. The backup bucket name _BUCKET_NAME_. (The bucket name in Google Cloud Storage object storage)
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=gcp \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set initContainers[0].name=velero-plugin-for-gcp \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-gcp:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

.. Then, suggests creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider gcp \
    --bucket <BUCKET_SLAVE_NAME>
----

. Azure
.. The backup bucket name _BUCKET_NAME_. (The bucket name in Azure Blob Storage object storage)
.. The resource group name __AZURE_RESOURCE_GROUP__. (The Azure resource group name)
.. The storage account ID __AZURE_STORAGE_ACCOUNT_ID__. (The Azure storage account ID)
.. The Velero installed namespace _NAMESPACE_, the default namespace is `velero`. (optional)
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=azure \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.resourceGroup=<AZURE_RESOURCE_GROUP> \
	--set configuration.backupStorageLocation.config.storageAccount=<AZURE_STORAGE_ACCOUNT_ID> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set initContainers[0].name=velero-plugin-for-microsoft-azure \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-microsoft-azure:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

.. Then, suggests creating at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider azure \
    --bucket <BUCKET_SLAVE_NAME> \
    --region resourceGroup=<AZURE_RESOURCE_GROUP>,storageAccount=<AZURE_STORAGE_ACCOUNT_ID>
----

==== The backup location on S3-compatible storage providers.

. The backup bucket name _BUCKET_NAME_. (The bucket name in S3 object storage)
. The backup region name _REGION_NAME_. (The region name for the S3 object storage. For example, radosgw _or_ master/slave if you have HA S3 object storage backups)
. The S3-compatible object storage simulates the S3 object storage. Therefore, the configuration for S3-compatible object storage have to setup additional configurations
+
[source,bash]
----
configuration.backupStorageLocation.config.s3ForcePathStyle=true
configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER__URL>
----
+
[NOTE]
Mostly the on-premise persistent volume does not support snapshot API or does not have community-supported snapshotter providers (for example, the NFS volume does not support the snapshot API). Therefore, we _have to_ deploy the `restic` DaemonSet.
+
[source,bash]
----
helm install \
    --name velero \
    --namespace <NAMESPACE> \
    --set-file credentials.secretContents.cloud=credentials-velero \
    --set configuration.provider=aws \
    --set configuration.backupStorageLocation.name=default \
    --set configuration.backupStorageLocation.name=<BUCKET_NAME> \
    --set configuration.backupStorageLocation.config.region=<REGION_NAME> \
    --set configuration.backupStorageLocation.config.s3ForcePathStyle=true \
    --set configuration.backupStorageLocation.config.s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL> \
    --set snapshotsEnabled=true \
    --set deployRestic=true \
    --set configuration.volumeSnapshotLocation.name=default \
    --set configuration.volumeSnapshotLocation.config.region=minio \
    --set initContainers[0].name=velero-plugin-for-aws \
    --set initContainers[0].image=registry.suse.com/caasp/v4/velero-plugin-for-aws:1.0.1 \
    --set initContainers[0].volumeMounts[0].mountPath=/target \
    --set initContainers[0].volumeMounts[0].name=plugins \
    suse/velero
----
+
[NOTE]
====
If Velero installed other than default namespace `velero`, setup velero config config to the Velero installed namespace.
----
velero client config set namespace=<NAMESPACE>
----
====

. Then, suggest to create at least one additional backup locations point to the different object storage server to prevent object storage server single point of failure.
+
[source,bash]
----
velero backup-location create slave \
    --provider aws \
    --bucket <BUCKET_SLAVE_NAME> \
    --config region=slave,s3ForcePathStyle=true,s3Url=<S3_COMPATIBLE_STORAGE_SERVER_URL>
----

[NOTE]
For troubleshooting a velero deployment, refer to link:https://velero.io/docs/v1.3.1/debugging-install/[Velero: Debugging Installation Issues]
