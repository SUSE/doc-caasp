[#monitoring-stack]
= Monitoring Stack

[IMPORTANT]
====
The described monitoring approach in this document is a generalized example of one way of monitoring a {productname} cluster.

Please apply best practices to develop your own monitoring approach using the described examples and available health checking endpoints.
====

== Introduction

This document aims to describe monitoring in a {kube} cluster.

The monitoring stack consists of a metrics server and a visualization platform.

* *Prometheus*
+
Prometheus is an open-source metrics server with a dimensional data model, flexible query language, efficient time series database and modern alerting approach. The time series collection happens via a pull mode over HTTP.
+
The Prometheus consists of multiple components:
+
 ** Prometheus server: scrapes and stores data to time series database
 ** https://prometheus.io/docs/alerting/alertmanager/[Alertmanager] handles client alerts, sanitizes duplicates and noise and routes them to configurable receivers.
 ** https://prometheus.io/docs/practices/pushing/[Pushgateway] is an intermediate service which allows you to push metrics from jobs which cannot be scraped.
+
[NOTE]
====
Deploying Prometheus https://prometheus.io/docs/practices/pushing/[Pushgateway] is out of the scope of this document.
====
 ** https://prometheus.io/docs/instrumenting/exporters/[Exporters] are libraries which help to exports existing metrics from 3rd-party system as Prometheus metric.

* *Grafana*
+
Grafana is an open-source system for querying, analysing and visualizing metrics.

== Prerequisites

. NGINX Ingress Controller
+
Please refer to <<nginx-ingress>> on how to configure ingress in your cluster. Deploying NGINX Ingress Controller also allows us to provide TLS termination to our services and to provide basic authentication to the Prometheus Expression browser/API.

. Create DNS entries
+
.Subdomains VS. Subpaths
[IMPORTANT]
====
There will be two different ways of using ingress for accessing the monitoring system.
One will be using `subdomains` such as `+prometheus.example.com+`, `+prometheus-alertmanager.example.com+`, and `+grafana.example.com+`.
Another deployment will be using `subpaths` for accessing monitoring system such as `example.com/prometheus`, `example.com/alertmanager`, and `example.com/grafana`.
====
+
In this example, we will use a master node with IP `10.86.4.158` in the case of NodePort service of the Ingress Controller.
+
.. Installation example of `subdomains`
+
NOTE: You should configure proper DNS names in any production environment.
These values are only for example purposes.
+
----
monitoring.example.com                      IN  A       10.86.4.158
prometheus.example.com                      IN  CNAME   monitoring.example.com
prometheus-alertmanager.example.com         IN  CNAME   monitoring.example.com
grafana.example.com                         IN  CNAME   monitoring.example.com
----
+
Or add this entry to `/etc/hosts`
+
----
10.86.4.158 prometheus.example.com prometheus-alertmanager.example.com grafana.example.com
----
+
.. Installation example of `subpaths`
+
----
example.com                      IN  A       10.86.4.158
----
+
Or add this entry to `/etc/hosts`
+
----
10.86.4.158 example.com
----

. Monitoring namespace
+
We will deploy our monitoring stack in its own namespace and therefore create one.
+
[source,bash]
----
kubectl create namespace monitoring
----

. Configure Authentication
+
We need to create a `basic-auth` secret so the NGINX Ingress Controller can perform authentication.
+
Install `apache2-utils`, which contains `htpasswd`, on your local workstation.
+
[source,bash]
----
zypper in apache2-utils
----
+
Create the secret file `auth`
+
[source,bash]
----
htpasswd -c auth admin
New password:
Re-type new password:
Adding password for user admin
----
+
[IMPORTANT]
====
It is very important that the filename is `auth`.
During creation, a key in the configuration containing the secret is created that is named after the used filename.
The ingress controller will expect a key named `auth`. And when you access the monitoring WebUI, you need to enter the username and password.
====
+
Create secret in {kube} cluster
+
[source,bash]
----
kubectl create secret generic -n monitoring prometheus-basic-auth --from-file=auth
----

. TLS
+
You must configure your certificates for the components as secrets in the {kube} cluster.
Get certificates from your local certificate authority.
In this example we are using a single certificate shared by the components `prometheus.example.com`, `prometheus-alertmanager.example.com` and `grafana.example.com`.
+
.Create Individual Secrets For Components
[NOTE]
====
Should you choose to secure each service with an individual certificate, you must repeat the step below for each component and adjust the name for the individual secret each time.

In this example the name is `monitoring-tls`.
====
+
.Note Down Secret Names For Configuration
[IMPORTANT]
====
You need to make sure the TLS secret you created came from a certificate that contains a Common Name (CN),
also known as a Fully Qualified Domain Name (FQDN) for example.com.

Please note down the names of the secrets you have created.
Later configuration steps require secret names to be specified.
====
+
.. Trusted Certificates
+
Please refer to <<trusted-server-certificate>> on how to sign the trusted certificate.
The `server.conf` for DNS.1 is `prometheus.example.com`, DNS.2 is `prometheus-alertmanager.example.com` and DNS.3 `grafana.example.com`.
+
Then, import your trusted certificate into the {kube} cluster.
In this example, trusted certificates are `monitoring.key` and `monitoring.crt`.
+
.. Self-signed Certificates (optional)
+
Please refer to <<self-signed-server-certificate>> on how to sign the self-signed certificate.
The `server.conf` for DNS.1 is `+prometheus.example.com+`, DNS.2 is `+prometheus-alertmanager.example.com+` and DNS.3 `+grafana.example.com+`.
+
Then, import your self-signed certificate into the {kube} cluster.
In this example, self-signed certificates are `monitoring.key` and `monitoring.crt`.
+
.. Add TLS secret to {kube} cluster from trusted Certificates or self-signed Certificates
+
[source,bash]
----
kubectl create -n monitoring secret tls monitoring-tls  \
--key  ./monitoring.key \
--cert ./monitoring.crt
----

== Installation

There will be two different ways of using ingress for accessing the monitoring system.

- <<installation-for-subdomains>>: Using `subdomains` for accessing monitoring system such as `+prometheus.example.com+`, `+prometheus-alertmanager.example.com+`, and `+grafana.example.com+`.

- <<installation-for-subpaths>>: Using `subpaths` for accessing monitoring system such as `example.com/prometheus`, `example.com/alertmanager`, and `example.com/grafana`.

[#installation-for-subdomains]
=== Installation For Subdomains

[NOTE]
====
This installation example shows how to install and configure Prometheus and Grafana using subdomains such as `prometheus.example.com`, `prometheus-alertmanager.example.com`, and `grafana.example.com`.
====

[IMPORTANT]
====
In order to provide additional security by using TLS certificates, please make sure you have the <<nginx-ingress>> installed and configured.

If you don't need TLS, you may use other methods for exposing these web services as native `LBaaS` in OpenStack, haproxy service or k8s native methods as port-forwarding or NodePort but this is out of scope of this document.
====

==== Prometheus

. Create a configuration file `prometheus-config-values.yaml`
+
We need to configure the storage for our deployment.
Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.

** Use an existing `PersistentVolumeClaim`
** Use a `StorageClass` (preferred)

+
----
# Alertmanager configuration
alertmanager:
  enabled: true
  ingress:
    enabled: true
    hosts:
    -  prometheus-alertmanager.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus-alertmanager.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 2Gi
    size: 2Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Alertmanager is configured through alertmanager.yml. This file and any others
## listed in alertmanagerFiles will be mounted into the alertmanager pod.
## See configuration options https://prometheus.io/docs/alerting/configuration/
#alertmanagerFiles:
#  alertmanager.yml:

# Create a specific service account
serviceAccounts:
  nodeExporter:
    name: prometheus-node-exporter

# Node tolerations for node-exporter scheduling to nodes with taints
# Allow scheduling of node-exporter on master nodes
nodeExporter:
  hostNetwork: false
  hostPID: false
  podSecurityPolicy:
    enabled: true
    annotations:
      apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
      apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
      seccomp.security.alpha.kubernetes.io/allowedProfileNames: runtime/default
      seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default
  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule

# Disable Pushgateway
pushgateway:
  enabled: false

# Prometheus configuration
server:
  ingress:
    enabled: true
    hosts:
    - prometheus.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 8Gi
    size: 8Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Prometheus is configured through prometheus.yml. This file and any others
## listed in serverFiles will be mounted into the server pod.
## See configuration options
## https://prometheus.io/docs/prometheus/latest/configuration/configuration/
#serverFiles:
#  prometheus.yml:
----
. Add SUSE helm charts repository
+
[source,bash]
----
helm repo add suse https://kubernetes-charts.suse.com
----

. Deploy SUSE `prometheus` helm chart and pass our configuration values file.
+
[source,bash]
----
helm install --name prometheus suse/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml
----
+
Or if you have selected the Helm 3 alternative also see <<helm-tiller-install>>:
+
[source,bash]
----
helm install prometheus suse/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml
----
+
There need to be 3 pods running (3 node-exporter pods because we have 3 nodes).
+
[source,bash]
----
kubectl -n monitoring get pod | grep prometheus
NAME                                             READY     STATUS    RESTARTS   AGE
prometheus-alertmanager-5487596d54-kcdd6         2/2       Running   0          2m
prometheus-kube-state-metrics-566669df8c-krblx   1/1       Running   0          2m
prometheus-node-exporter-jnc5w                   1/1       Running   0          2m
prometheus-node-exporter-qfwp9                   1/1       Running   0          2m
prometheus-node-exporter-sc4ls                   1/1       Running   0          2m
prometheus-server-6488f6c4cd-5n9w8               2/2       Running   0          2m
----
+
There need to be be 2 ingresses configured
+
[source,bash]
----
kubectl get ingress -n monitoring
NAME                      HOSTS                                 ADDRESS   PORTS     AGE
prometheus-alertmanager   prometheus-alertmanager.example.com             80, 443   87s
prometheus-server         prometheus.example.com                          80, 443   87s
----

. At this stage, the Prometheus Expression browser/API should be accessible, depending on your network configuration
* **NodePort**: `+https://prometheus.example.com:32443+`
* **External IPs**: `+https://prometheus.example.com+`
* **LoadBalancer**: `+https://prometheus.example.com+`

[#alertmanager-configuration-example]
==== Alertmanager Configuration Example

The configuration example sets one "receiver" to get notified by email when one of below conditions is met:

* Node is unschedulable: severity is `critical` because the node cannot accept new pods
* Node runs out of disk space: severity is `critical` because the node cannot accept new pods
* Node has memory pressure: severity is `warning`
* Node has disk pressure: severity is `warning`
* Certificates is going to expire in 7 days: severity is `critical`
* Certificates is going to expire in 30 days: severity is `warning`
* Certificates is going to expire in 3 months: severity is `info`

. Configure alerting receiver in Alertmanager
+
The Alertmanager handles alerts sent by Prometheus server, it takes care of deduplicating, grouping, and routing them to the correct receiver integration such as email. It also takes care of silencing and inhibition of alerts.
+
Add the `alertmanagerFiles` section to your Prometheus configuration file `prometheus-config-values.yaml`.
+
For more information on how to configure Alertmanager, refer to link:https://prometheus.io/docs/alerting/configuration[Prometheus: Alerting - Configuration].
+
----
alertmanagerFiles:
  alertmanager.yml:
    global:
      # The smarthost and SMTP sender used for mail notifications.
      smtp_from: alertmanager@example.com
      smtp_smarthost: smtp.example.com:587
      smtp_auth_username: admin@example.com
      smtp_auth_password: <PASSWORD>
      smtp_require_tls: true

    route:
      # The labels by which incoming alerts are grouped together.
      group_by: ['node']

      # When a new group of alerts is created by an incoming alert, wait at
      # least 'group_wait' to send the initial notification.
      # This way ensures that you get multiple alerts for the same group that start
      # firing shortly after another are batched together on the first
      # notification.
      group_wait: 30s

      # When the first notification was sent, wait 'group_interval' to send a batch
      # of new alerts that started firing for that group.
      group_interval: 5m

      # If an alert has successfully been sent, wait 'repeat_interval' to
      # resend them.
      repeat_interval: 3h

      # A default receiver
      receiver: admin-example

    receivers:
    - name: 'admin-example'
      email_configs:
      - to: 'admin@example.com'
----
. Configures alerting rules in Prometheus server
+
Replace the `serverFiles` section of the Prometheus configuration file `prometheus-config-values.yaml`.
+
For more information on how to configure alerts, refer to: link:https://prometheus.io/docs/alerting/notification_examples/[Prometheus: Alerting - Notification Template Examples]
+
----
serverFiles:
  alerts: {}
  rules:
    groups:
    - name: caasp.node.rules
      rules:
      - alert: NodeIsNotReady
        expr: kube_node_status_condition{condition="Ready",status="false"} == 1 or kube_node_status_condition{condition="Ready",status="unknown"} == 1
        for: 1m
        labels:
          severity: critical
        annotations:
          description: '{{ $labels.node }} is not ready'
      - alert: NodeIsOutOfDisk
        expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
        labels:
          severity: critical
        annotations:
          description: '{{ $labels.node }} has insufficient free disk space'
      - alert: NodeHasDiskPressure
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        labels:
          severity: warning
        annotations:
          description: '{{ $labels.node }} has insufficient available disk space'
      - alert: NodeHasInsufficientMemory
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        labels:
          severity: warning
        annotations:
          description: '{{ $labels.node }} has insufficient available memory'
    - name: caasp.certs.rules
      rules:
      - alert: KubernetesCertificateExpiry3Months
        expr: (cert_exporter_cert_expires_in_seconds / 86400) < 90
        labels:
          severity: info
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 3 months'
      - alert: KubernetesCertificateExpiry30Days
        expr: (cert_exporter_cert_expires_in_seconds / 86400) < 30
        labels:
          severity: warning
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 30 days'
      - alert: KubernetesCertificateExpiry7Days
        expr: (cert_exporter_cert_expires_in_seconds / 86400) < 7
        labels:
          severity: critical
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 7 days'
      - alert: KubeconfigCertificateExpiry3Months
        expr: (cert_exporter_kubeconfig_expires_in_seconds / 86400) < 90
        labels:
          severity: info
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 3 months'
      - alert: KubeconfigCertificateExpiry30Days
        expr: (cert_exporter_kubeconfig_expires_in_seconds / 86400) < 30
        labels:
          severity: warning
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 30 days'
      - alert: KubeconfigCertificateExpiry7Days
        expr: (cert_exporter_kubeconfig_expires_in_seconds / 86400) < 7
        labels:
          severity: critical
        annotations:
          description: 'The cert for {{ $labels.filename }} on {{ $labels.nodename }} node is going to expire in 7 days'
      - alert: AddonCertificateExpiry3Months
        expr: (cert_exporter_secret_expires_in_seconds / 86400) < 90
        labels:
          severity: info
        annotations:
          description: 'The cert for {{ $labels.secret_name }} is going to expire in 3 months'
      - alert: AddonCertificateExpiry30Days
        expr: (cert_exporter_secret_expires_in_seconds / 86400) < 30
        labels:
          severity: warning
        annotations:
          description: 'The cert for {{ $labels.secret_name }} is going to expire in 30 days'
      - alert: AddonCertificateExpiry7Days
        expr: (cert_exporter_secret_expires_in_seconds / 86400) < 7
        labels:
          severity: critical
        annotations:
          description: 'The cert for {{ $labels.secret_name }} is going to expire in 7 days'
----
. To apply the changed configuration, run:
+
----
helm upgrade prometheus suse/prometheus --namespace monitoring --values prometheus-config-values.yaml
----
. You should now be able to see your Alertmanager, depending on your network configuration
* **NodePort**: `+https://prometheus-alertmanager.example.com:32443+`
* **External IPs**: `+https://prometheus-alertmanager.example.com+`
* **LoadBalancer**: `+https://prometheus-alertmanager.example.com+`

[#recording-rules-configuration-example]
==== Recording Rules Configuration Example

Recording rules allow you to precompute frequently needed or computationally
expensive expressions and save their result as a new set of time series.
Querying the precomputed result will then often be much faster than executing
the original expression every time it is needed. This is especially useful for
dashboards, which need to query the same expression repeatedly every time they
refresh. Another common use case is federation where precomputed metrics are
scraped from one Prometheus instance by another.

For more information on how to configure recording rules, refer to
link:https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#recording-rules[Prometheus:Recording Rules - Configuration].

. Configuring recording rules
+
Add the following group of rules in the `serverFiles` section of the `prometheus-config-values.yaml` configuration file.
+
----
serverFiles:
  alerts: {}
  rules:
    groups:
    - name: node-exporter.rules
      rules:
      - expr: count by (instance) (count without (mode) (node_cpu_seconds_total{component="node-exporter"}))
        record: instance:node_num_cpu:sum
      - expr: 1 - avg by (instance) (rate(node_cpu_seconds_total{component="node-exporter",mode="idle"}[5m]))
        record: instance:node_cpu_utilisation:rate5m
      - expr: node_load1{component="node-exporter"} / on (instance) instance:node_num_cpu:sum
        record: instance:node_load1_per_cpu:ratio
      - expr: node_memory_MemAvailable_bytes / on (instance) node_memory_MemTotal_bytes
        record: instance:node_memory_utilisation:ratio
      - expr: rate(node_vmstat_pgmajfault{component="node-exporter"}[5m])
        record: instance:node_vmstat_pgmajfault:rate5m
      - expr: rate(node_disk_io_time_seconds_total{component="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[5m])
        record: instance_device:node_disk_io_time_seconds:rate5m
      - expr: rate(node_disk_io_time_weighted_seconds_total{component="node-exporter", device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[5m])
        record: instance_device:node_disk_io_time_weighted_seconds:rate5m
      - expr: sum by (instance) (rate(node_network_receive_bytes_total{component="node-exporter", device!="lo"}[5m]))
        record: instance:node_network_receive_bytes_excluding_lo:rate5m
      - expr: sum by (instance) (rate(node_network_transmit_bytes_total{component="node-exporter", device!="lo"}[5m]))
        record: instance:node_network_transmit_bytes_excluding_lo:rate5m
      - expr: sum by (instance) (rate(node_network_receive_drop_total{component="node-exporter", device!="lo"}[5m]))
        record: instance:node_network_receive_drop_excluding_lo:rate5m
      - expr: sum by (instance) (rate(node_network_transmit_drop_total{component="node-exporter", device!="lo"}[5m]))
        record: instance:node_network_transmit_drop_excluding_lo:rate5m
----
. To apply the changed configuration, run:
+
----
helm upgrade prometheus suse/prometheus --namespace monitoring --values prometheus-config-values.yaml
----
. You should now be able to see your configured rules, depending on your network configuration
* **NodePort**: `+https://prometheus.example.com:32443/rules+`
* **External IPs**: `+https://prometheus.example.com/rules+`
* **LoadBalancer**: `+https://prometheus.example.com/rules+`

==== Grafana

Starting from Grafana 5.0, it is possible to dynamically provision the data sources and dashboards via files.
In a {kube} cluster, these files are provided via the utilization of `ConfigMap`, editing a `ConfigMap` will result by the modification of the configuration without having to delete/recreate the pod.

. Configure Grafana provisioning
+
Create the default datasource configuration file `grafana-datasources.yaml` which point to our Prometheus server
+
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: grafana-datasources
  namespace: monitoring
  labels:
     grafana_datasource: "1"
data:
  datasource.yaml: |-
    apiVersion: 1
    deleteDatasources:
      - name: Prometheus
        orgId: 1
    datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-server.monitoring.svc.cluster.local:80
      access: proxy
      orgId: 1
      isDefault: true
----

. Create the `ConfigMap` in {kube} cluster
+
[source,bash]
----
kubectl create -f grafana-datasources.yaml
----

. Configure storage for the deployment
+
Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.

** Use an existing `PersistentVolumeClaim`
** Use a `StorageClass` (preferred)
+
Create a file `grafana-config-values.yaml` with the appropriate values
+
----
# Configure admin password
adminPassword: <PASSWORD>

# Ingress configuration
ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
  hosts:
    - grafana.example.com
  tls:
    - hosts:
      - grafana.example.com
      secretName: monitoring-tls

# Configure persistent storage
persistence:
  enabled: true
  accessModes:
    - ReadWriteOnce
  ## Use a StorageClass
  storageClassName: my-storage-class
  ## Create a PersistentVolumeClaim of 10Gi
  size: 10Gi
  ## Use an existing PersistentVolumeClaim (my-pvc)
  #existingClaim: my-pvc

# Enable sidecar for provisioning
sidecar:
  datasources:
    enabled: true
    label: grafana_datasource
  dashboards:
    enabled: true
    label: grafana_dashboard
----

. Add SUSE helm charts repository
+
[source,bash]
----
helm repo add suse https://kubernetes-charts.suse.com
----
. Deploy SUSE grafana helm chart and pass our configuration values file
+
[source,bash]
----
helm install --name grafana suse/grafana \
--namespace monitoring \
--values grafana-config-values.yaml
----
Or if you have selected the Helm 3 alternative also see <<helm-tiller-install>>:
+
[source,bash]
----
helm install grafana suse/grafana \
--namespace monitoring \
--values grafana-config-values.yaml
----

. The result should be a running Grafana pod
+
[source,bash]
----
kubectl -n monitoring get pod | grep grafana
NAME                                             READY     STATUS    RESTARTS   AGE
grafana-dbf7ddb7d-fxg6d                          3/3       Running   0          2m
----

. At this stage, Grafana should be accessible, depending on your network configuration

* **NodePort**: `+https://grafana.example.com:32443+`
* **External IPs**: `+https://grafana.example.com+`
* **LoadBalancer**: `+https://grafana.example.com+`

. Now you can add Grafana dashboards.

[#adding-grafana-dashboards]
==== Adding Grafana Dashboards

There are three ways to add dashboards to Grafana:

* Deploy an existing dashboard from link:https://grafana.com/dashboards[Grafana dashboards]
  . Open the deployed Grafana in your browser and log in.
  . On the home page of Grafana, hover your mousecursor over the + button on the left sidebar and click on the import menuitem.
  . Select an existing dashboard for your purpose from Grafana dashboards. Copy the URL to the clipboard.
  . Paste the URL (for example) `+https://grafana.com/dashboards/3131+` into the first input field to import the "Kubernetes All Nodes" Grafana Dashboard.
After pasting in the url, the view will change to another form.
  . Now select the "Prometheus" datasource in the `prometheus` field and click on the import button.
  . The browser will redirect you to your newly created dashboard.

* Use our link:https://github.com/SUSE/caasp-monitoring[pre-built dashboards] to monitor the {productname} system

+
[source,bash]
----
# monitor SUSE CaaS Platform cluster
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-cluster.yaml
# monitor SUSE CaaS Platform etcd cluster
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-etcd-cluster.yaml
# monitor SUSE CaaS Platform nodes
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-nodes.yaml
# monitor SUSE CaaS Platform namespaces
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-namespaces.yaml
# monitor SUSE CaaS Platform pods
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-pods.yaml
# monitor SUSE CaaS Platform certificates
kubectl apply -f https://raw.githubusercontent.com/SUSE/caasp-monitoring/master/grafana-dashboards-caasp-certificates.yaml
----

* Build your own dashboard
  Deploy your own dashboard by configuration file containing the dashboard definition.

. Create your dashboard definition file as a `ConfigMap`, for example `grafana-dashboards-caasp-cluster.yaml`.
+
----
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-dashboards-caasp-cluster
  namespace: monitoring
  labels:
     grafana_dashboard: "1"
data:
  caasp-cluster.json: |-
    {
      "__inputs": [
        {
          "name": "DS_PROMETHEUS",
          "label": "Prometheus",
          "description": "",
          "type": "datasource",
          "pluginId": "prometheus",
          "pluginName": "Prometheus"
        }
      ],
      "__requires": [
        {
          "type": "grafana",
[...]
continues with definition of dashboard JSON
[...]
----

. Apply the `ConfigMap` to the cluster.
+
[source,bash]
----
kubectl apply -f grafana-dashboards-caasp-cluster.yaml
----

[#installation-for-subpaths]
=== Installation For Subpaths

[NOTE]
====
This installation example shows how to install and configure Prometheus and Grafana using subpaths such as example.com/prometheus, example.com/alertmanager, and example.com/grafana.
====

[IMPORTANT]
====
Overlapped instructions from subdomains will be omitted. Refer to the instruction from subdomains.
====

==== Prometheus

. Create a configuration file `prometheus-config-values.yaml`
+
We need to configure the storage for our deployment.
Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.

** Use an existing `PersistentVolumeClaim`
** Use a `StorageClass` (preferred)
** Disable ingresses
** Add the external url at which the server can be accessed
+
----
# Alertmanager configuration
alertmanager:
  enabled: true
  ingress:
    enabled: false
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 2Gi
    size: 2Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Alertmanager is configured through alertmanager.yml. This file and any others
## listed in alertmanagerFiles will be mounted into the alertmanager pod.
## See configuration options https://prometheus.io/docs/alerting/configuration/
#alertmanagerFiles:
#  alertmanager.yml:

# Create a specific service account
serviceAccounts:
  nodeExporter:
    name: prometheus-node-exporter

# Node tolerations for node-exporter scheduling to nodes with taints
# Allow scheduling of node-exporter on master nodes
nodeExporter:
  hostNetwork: false
  hostPID: false
  podSecurityPolicy:
    enabled: true
    annotations:
      apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
      apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
      seccomp.security.alpha.kubernetes.io/allowedProfileNames: runtime/default
      seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default
  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule

# Disable Pushgateway
pushgateway:
  enabled: false

# Prometheus configuration
server:
  baseURL: https://example.com:32443/prometheus
  prefixURL: /prometheus
  ingress:
    enabled: false
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 8Gi
    size: 8Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Prometheus is configured through prometheus.yml. This file and any others
## listed in serverFiles will be mounted into the server pod.
## See configuration options
## https://prometheus.io/docs/prometheus/latest/configuration/configuration/
#serverFiles:
#  prometheus.yml:
----
. Add SUSE helm charts repository
+
[source,bash]
----
helm repo add suse https://kubernetes-charts.suse.com
----
+
. Deploy SUSE prometheus helm chart and pass our configuration values file.
+
[source,bash]
----
helm install --name prometheus suse/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml
----
+
Or if you have selected the Helm 3 alternative also see <<helm-tiller-install>>:
+
[source,bash]
----
helm install prometheus suse/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml
----
+
There need to be 3 pods running (3 node-exporter pods because we have 3 nodes).
+
[source,bash]
----
kubectl -n monitoring get pod | grep prometheus
NAME                                             READY     STATUS    RESTARTS   AGE
prometheus-alertmanager-5487596d54-kcdd6         2/2       Running   0          2m
prometheus-kube-state-metrics-566669df8c-krblx   1/1       Running   0          2m
prometheus-node-exporter-jnc5w                   1/1       Running   0          2m
prometheus-node-exporter-qfwp9                   1/1       Running   0          2m
prometheus-node-exporter-sc4ls                   1/1       Running   0          2m
prometheus-server-6488f6c4cd-5n9w8               2/2       Running   0          2m
----

==== Alertmanager Configuration Example
Refer to <<alertmanager-configuration-example>>

==== Recording Rules Configuration Example
Refer to <<recording-rules-configuration-example>>

==== Grafana

Starting from Grafana 5.0, it is possible to dynamically provision the data sources and dashboards via files.
In {kube} cluster, these files are provided via the utilization of `ConfigMap`, editing a `ConfigMap` will result by the modification of the configuration without having to delete/recreate the pod.

. Configure Grafana provisioning
+
Create the default datasource configuration file `grafana-datasources.yaml` which point to our Prometheus server
+
----
---
kind: ConfigMap
apiVersion: v1
metadata:
  name: grafana-datasources
  namespace: monitoring
  labels:
     grafana_datasource: "1"
data:
  datasource.yaml: |-
    apiVersion: 1
    deleteDatasources:
      - name: Prometheus
        orgId: 1
    datasources:
    - name: Prometheus
      type: prometheus
      url: http://prometheus-server.monitoring.svc.cluster.local:80
      access: proxy
      orgId: 1
      isDefault: true
----

. Create the `ConfigMap` in {kube} cluster
+
[source,bash]
----
kubectl create -f grafana-datasources.yaml
----

. Configure storage for the deployment
+
Choose among the options and uncomment the line in the config file.
In production environments you must configure persistent storage.

** Use an existing `PersistentVolumeClaim`
** Use a `StorageClass` (preferred)
** Disable ingress
** Add the subpath to the end of this URL setting.
+
Create a file `grafana-config-values.yaml` with the appropriate values
+
----
# Configure admin password
adminPassword: <PASSWORD>

# Ingress configuration
ingress:
  enabled: false

# subpath for grafana
grafana.ini:
  server:
    root_url: https://example.com:32443/grafana

# Configure persistent storage
persistence:
  enabled: true
  accessModes:
    - ReadWriteOnce
  ## Use a StorageClass
  storageClassName: my-storage-class
  ## Create a PersistentVolumeClaim of 10Gi
  size: 10Gi
  ## Use an existing PersistentVolumeClaim (my-pvc)
  #existingClaim: my-pvc

# Enable sidecar for provisioning
sidecar:
  datasources:
    enabled: true
    label: grafana_datasource
  dashboards:
    enabled: true
    label: grafana_dashboard
----

. Add SUSE helm charts repository
+
[source,bash]
----
helm repo add suse https://kubernetes-charts.suse.com
----
. Deploy SUSE grafana helm chart and pass our configuration values file
+
[source,bash]
----
helm install --name grafana suse/grafana \
--namespace monitoring \
--values grafana-config-values.yaml
----
+
Or if you have selected the Helm 3 alternative also see <<helm-tiller-install>>:
+
[source,bash]
----
helm install grafana suse/grafana \
--namespace monitoring \
--values grafana-config-values.yaml
----

. The result should be a running Grafana pod
+
[source,bash]
----
kubectl -n monitoring get pod | grep grafana
NAME                                             READY     STATUS    RESTARTS   AGE
grafana-dbf7ddb7d-fxg6d                          3/3       Running   0          2m
----

==== Ingress
. Configure Ingress for Prometheus
Create a file `prometheus-ingress.yaml`
+
----
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: prometheus-ingress
  namespace: monitoring
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
spec:
  tls:
    - hosts:
      - example.com
      secretName: monitoring-tls
  rules:
  - host: example.com
    http:
      paths:
      - path: /prometheus
        backend:
          serviceName: prometheus-server
          servicePort: 80
----
Deploy the prometheus ingress file
+
[source,bash]
----
kubectl apply -f prometheus-ingress.yaml
----
Verify the prometheus ingress
+
[source,bash]
----
kubectl -n monitoring get ingress | grep prometheus
NAME                         HOSTS         ADDRESS   PORTS     AGE
prometheus-ingress           example.com             80, 443   11s
----

. Configure Ingress for Alertmanager and Grafana
Create a file `alertmanager-grafana-ingress.yaml`
+
----
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: alertmanager-grafana-ingress
  namespace: monitoring
  annotations:
    kubernetes.io/ingress.class: nginx
    nginx.ingress.kubernetes.io/auth-type: basic
    nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
    nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  tls:
    - hosts:
      - example.com
      secretName: monitoring-tls
  rules:
  - host: example.com
    http:
      paths:
      - path: /alertmanager
        backend:
          serviceName: prometheus-alertmanager
          servicePort: 80

      - path: /grafana
        backend:
          serviceName: grafana
          servicePort: 80
----
Deploy the alertmanager and grafana ingress file
+
[source,bash]
----
kubectl apply -f alertmanager-grafana-ingress.yaml
----
Verify the alertmanager and grafana ingress
+
[source,bash]
----
kubectl -n monitoring get ingress | grep grafana
NAME                          HOSTS         ADDRESS   PORTS     AGE
alertmanager-grafana-ingress  example.com             80, 443   11s
----

. Access Prometheus, Alertmanager, and Grafana
+
At this stage, the Prometheus Expression browser/API, Alertmanager, and Grafana should be accessible, depending on your network configuration
+
* Prometheus Expression browser/API
** **NodePort**: `+https://example.com:32443/prometheus+`
** **External IPs**: `+https://example.com/prometheus+`
** **LoadBalancer**: `+https://example.com/prometheus+`
+
* Alertmanager
** **NodePort**: `+https://example.com:32443/alertmanger+`
** **External IPs**: `+https://example.com/alertmanger+`
** **LoadBalancer**: `+https://example.com/alertmanger+`
+
* Grafana
** **NodePort**: `+https://example.com:32443/grafana+`
** **External IPs**: `+https://example.com/grafana+`
** **LoadBalancer**: `+https://example.com/grafana+`

. Now you can add the Grafana dashboards.

==== Adding Grafana Dashboards
Refer to <<adding-grafana-dashboards>>

== Monitoring

=== Prometheus Jobs

The Prometheus SUSE helm chart includes the following predefined jobs that will scrape metrics from these jobs using service discovery.

* prometheus: Get metrics from prometheus server
* kubernetes-apiservers: Get metrics from {kube} apiserver
* kubernetes-nodes: Get metrics from {kube} nodes
* kubernetes-service-endpoints: Get metrics from Services which have annotation `prometheus.io/scrape=true` in the metadata
* kubernetes-pods: Get metrics from Pods which have annotation `prometheus.io/scrape=true` in the metadata

If you want to monitor new pods and services, you don't need to change `prometheus.yaml` but add annotation `prometheus.io/scrape=true`, `prometheus.io/port=<TARGET_PORT>` and `prometheus.io/path=<METRIC_ENDPOINT>` to your pods and services metadata. Prometheus will automatically scrape the target.

=== ETCD Cluster

ETCD server exposes metrics on the `/metrics` endpoint. Prometheus jobs do not scrape it by default. Edit the `prometheus.yaml` file if you want to monitor the etcd cluster. Since the etcd cluster runs on https, we need to create a certificate to access the endpoint.

. Create a new etcd client certificate signed by etcd CA cert/key pair:
+
[source,bash]
----
cat << EOF > my-cluster/pki/etcd/openssl-monitoring-client.conf
[req]
distinguished_name = req_distinguished_name
req_extensions = v3_req
prompt = no

[v3_req]
keyUsage = digitalSignature,keyEncipherment
extendedKeyUsage = clientAuth

[req_distinguished_name]
O = system:masters
CN = kube-etcd-monitoring-client
EOF

openssl req -nodes -new -newkey rsa:2048 -config my-cluster/pki/etcd/openssl-monitoring-client.conf -out my-cluster/pki/etcd/monitoring-client.csr -keyout my-cluster/pki/etcd/monitoring-client.key
openssl x509 -req -days 365 -CA my-cluster/pki/etcd/ca.crt -CAkey my-cluster/pki/etcd/ca.key -CAcreateserial -in my-cluster/pki/etcd/monitoring-client.csr -out my-cluster/pki/etcd/monitoring-client.crt -sha256 -extfile my-cluster/pki/etcd/openssl-monitoring-client.conf -extensions v3_req
----

. Create the etcd client certificate to secret in monitoring namespace:
+
[source,bash]
----
kubectl -n monitoring create secret generic etcd-certs --from-file=my-cluster/pki/etcd/ca.crt --from-file=my-cluster/pki/etcd/monitoring-client.crt --from-file=my-cluster/pki/etcd/monitoring-client.key
----

. Get all etcd cluster private IP address:
+
[source,bash]
----
kubectl get pods -n kube-system -l component=etcd -o wide
NAME           READY   STATUS    RESTARTS   AGE   IP             NODE      NOMINATED NODE   READINESS GATES
etcd-master0   1/1     Running   2          21h   192.168.0.6    master0   <none>           <none>
etcd-master1   1/1     Running   2          21h   192.168.0.20   master1   <none>           <none>
----

. Edit the configuration file `prometheus-config-values.yaml`, add `extraSecretMounts` and `extraScrapeConfigs` parts, change the extraScrapeConfigs targets IP address(es) as your environment and change the target numbers if you have different etcd cluster members:
+
----
# Alertmanager configuration
alertmanager:
  enabled: true
  ingress:
    enabled: true
    hosts:
    -  prometheus-alertmanager.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus-alertmanager.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 2Gi
    size: 2Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc

## Alertmanager is configured through alertmanager.yml. This file and any others
## listed in alertmanagerFiles will be mounted into the alertmanager pod.
## See configuration options https://prometheus.io/docs/alerting/configuration/
#alertmanagerFiles:
#  alertmanager.yml:

# Create a specific service account
serviceAccounts:
  nodeExporter:
    name: prometheus-node-exporter

# Node tolerations for node-exporter scheduling to nodes with taints
# Allow scheduling of node-exporter on master nodes
nodeExporter:
  hostNetwork: false
  hostPID: false
  podSecurityPolicy:
    enabled: true
    annotations:
      apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default
      apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default
      seccomp.security.alpha.kubernetes.io/allowedProfileNames: runtime/default
      seccomp.security.alpha.kubernetes.io/defaultProfileName: runtime/default
  tolerations:
    - key: node-role.kubernetes.io/master
      operator: Exists
      effect: NoSchedule

# Disable Pushgateway
pushgateway:
  enabled: false

# Prometheus configuration
server:
  ingress:
    enabled: true
    hosts:
    - prometheus.example.com
    annotations:
      kubernetes.io/ingress.class: nginx
      nginx.ingress.kubernetes.io/auth-type: basic
      nginx.ingress.kubernetes.io/auth-secret: prometheus-basic-auth
      nginx.ingress.kubernetes.io/auth-realm: "Authentication Required"
    tls:
      - hosts:
        - prometheus.example.com
        secretName: monitoring-tls
  persistentVolume:
    enabled: true
    ## Use a StorageClass
    storageClass: my-storage-class
    ## Create a PersistentVolumeClaim of 8Gi
    size: 8Gi
    ## Use an existing PersistentVolumeClaim (my-pvc)
    #existingClaim: my-pvc
  ## Additional Prometheus server Secret mounts
  # Defines additional mounts with secrets. Secrets must be manually created in the namespace.
  extraSecretMounts:
  - name: etcd-certs
    mountPath: /etc/secrets
    secretName: etcd-certs
    readOnly: true

extraScrapeConfigs: |
  - job_name: etcd
    static_configs:
    - targets: ['192.168.0.32:2379','192.168.0.17:2379','192.168.0.5:2379']
    scheme: https
    tls_config:
      ca_file: /etc/secrets/ca.crt
      cert_file: /etc/secrets/monitoring-client.crt
      key_file: /etc/secrets/monitoring-client.key

## Prometheus is configured through prometheus.yml. This file and any others
## listed in serverFiles will be mounted into the server pod.
## See configuration options
## https://prometheus.io/docs/prometheus/latest/configuration/configuration/
#serverFiles:
#  prometheus.yml:
----

. Upgrade prometheus helm deployment:
+
[source,bash]
----
helm upgrade prometheus suse/prometheus \
--namespace monitoring \
--values prometheus-config-values.yaml
----
