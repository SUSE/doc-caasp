== Deployment on VMware

.Preparation Required
[NOTE]
You must have completed <<deployment.preparations>> to proceed.

=== Environment Description

[NOTE]
====
These instructions are based on `VMware ESXi {vmware_version}`.
====

[IMPORTANT]
====
These instructions currently do not describe how to set up a load balancer.
This will be added in future versions. You must provide your own load balancing
solution that directs access to the master nodes.
====

[IMPORTANT]
====
VMware vSPhere doesn't offer a load-balancer solution. Please expose port `6443`
for the {kube} api-servers on the master nodes on a local load balancer using
round-robin 1:1 port forwarding.
====

=== VM Preparation for Creating a Template

. Upload the ISO image {isofile} to the desired VMware datastore.

Now you can create a new base VM for {productname} within the designated resource
pool through the vSphere WebUI:

. Create a "New Virtual Machine".
. Define a name for the virtual machine (VM).
+
image::vmware_step1.png[width=80%,pdfwidth=80%]
. Select the folder where the VM will be stored.
. Select a `Compute Resource` that will run the VM.
+
image::vmware_step2.png[width=80%,pdfwidth=80%]
. Select the storage to be used by the VM.
+
image::vmware_step3.png[width=80%,pdfwidth=80%]
. Select `ESXi 6.7 and later` from compatibility.
+
image::vmware_step4.png[width=80%,pdfwidth=80%]
. Select menu:Guest OS Family[Linux] and menu:Guest OS Version[SUSE Linux Enterprise 15 (64-bit)].
+
*Note*: You will manually select the correct installation medium in the next step.
+
image::vmware_step5.png[width=80%,pdfwidth=80%]
. Now customize the hardware settings.
+
image::vmware_step6.png[width=80%,pdfwidth=80%]
.. Select menu:CPU[2].
.. Select menu:Memory[4096 MB].
.. Select menu:New Hard disk[40 GB], menu:New Hard disk[Disk Provisioning > Thin Provision].
.. Select menu:New SCSI Controller[LSI Logic Parallel SCSI controller (default)] and change it to "VMware Paravirtualized".
.. Select menu:New Network[VM Network], menu:New Network[Adapter Type > VMXNET3].
+
("VM Network" sets up a bridged network which provides a public IP address reachable within a company.)
.. Select menu:New CD/DVD[Datastore ISO File].
.. Check the box menu:New CD/DVD[Connect At Power On] to be able boot from ISO/DVD.
.. Then click on "Browse" next to the `CD/DVD Media` field to select the downloaded ISO image on the desired datastore.
.. Go to the VM Options tab.
+
image::vmware_step6b.png[width=80%,pdfwidth=80%]
.. Select menu:Boot Options[].
.. Select menu:Firmware[BIOS].
.. Confirm the process with menu:Next[].

==== {sls} Installation

Power on the newly created VM and install the system over graphical remote console:

. Enter product key for SLES in YaST.
. Confirm the update repositories prompt with "Yes".
. Remove the check mark in the "Hide Development Versions" box.
. Make sure the following modules are selected on the "Extension and Module Selection" screen:
+
image::vmware_extension.png[width=80%,pdfwidth=80%]
** SUSE CaaS Platform 4.0 x86_64 (BETA)
** Basesystem Module
** Containers Module (this will automatically be checked when you select {productname})
** Public Cloud Module
. Enter the product key to unlock the {productname} extension.
. Select menu:System Role[Minimal] on the "System Role" screen.
. Click on "Expert Partitioner" to redesign the default partition layout.
. Select "Start with current proposal".
+
image::vmware_step8.png[width=80%,pdfwidth=80%]
.. Keep `sda1` as BIOS partition.
.. Remove the root `/` partition.
+
Select the device in "System View" on the left (default: `/dev/sda2`) and click "Delete". Confirm with "Yes".
+
image::vmware_step9.png[width=80%,pdfwidth=80%]
.. Remove the `/home` partition.
.. Remove the `swap` partition.
. Select the `/dev/sda/` device in "System View" and then click menu:Partitions[Add Partition].
+
image::vmware_step10.png[width=80%,pdfwidth=80%]
. Accept the default maximum size (remaining size of the hard disk defined earlier without the boot partition).
+
image::vmware_step11.png[width=80%,pdfwidth=80%]
.. Confirm with "Next".
.. Select menu:Role[Operating System]
+
image::vmware_step12.png[width=80%,pdfwidth=80%]
.. Confirm with "Next".
.. Accept the default settings.
+
image::vmware_step13.png[width=80%,pdfwidth=80%]
*** Filesystem: BtrFS
*** Enable Snapshots
*** Mount Device
*** Mount Point `/`
. You should be left with two partitions. Now click "Accept".
+
image::vmware_step7.png[width=80%,pdfwidth=80%]
. Confirm the partitioning changes.
+
image::vmware_step14.png[width=80%,pdfwidth=80%]
. Click "Next".
. Configure your timezone and click "Next".
. Create a user with the username `sles` and specify a password.
.. Check the box menu:Local User[Use this password for system administrator].
+
image::vmware_step15.png[width=80%,pdfwidth=80%]
. Click "Next".
. On the "Installation Settings" screen:
.. In the "Security" section:
... Disable the Firewall (click on `(disable)`).
... Enable the SSH service (click on `(enable)`).
.. Scroll to the `kdump` section of the software description and click on the title.
. In the "Kdump Start-Up" screen, select menu:Enable/Disable Kdump[Disable Kdump].
.. Confirm with "OK".
+
image::vmware_step16.png[width=80%,pdfwidth=80%]
. Click "Install". Confirm the installation by clicking "Install" in the pop-up dialog.
. Finish the installation and confirm system reboot with "OK".
+
image::vmware_step17.png[width=80%,pdfwidth=80%]

==== Preparation of the VM as a Template

In order to run {productname} on the created VMs, you must configure and install some additional packages
like `sudo`, `cloud-init` and `open-vm-tools`.

.Activate extensions during {sle} installation with YaST
[TIP]
Steps 1-4 may be skipped, if they were already performed in YaST during the {sle} installation.

. Register the SLES15-SP1 system. Substitute `CAASP_PRODUCT_KEY` for the code from <<registration_code>>.
+
----
SUSEConnect -r CAASP_PRODUCT_KEY
----
. Register the `Containers` module (free of charge):
+
----
SUSEConnect -p sle-module-containers/15.1/x86_64
----
. Register the `Public Cloud` module for basic `cloud-init` package (free of charge):
+
----
SUSEConnect -p sle-module-public-cloud/15.1/x86_64
----
. Register the {productname} module. Substitute `CAASP_PRODUCT_KEY` for the code from <<registration_code>>.
+
----
SUSEConnect -p caasp/4.0/x86_64 -r CAASP_PRODUCT_KEY
----
. Install required packages. As root, run:
+
----
zypper in sudo cloud-init cloud-init-vmware-guestinfo open-vm-tools
----
. Enable the installed `cloud-init` services. As root, run:
+
----
systemctl enable cloud-init cloud-init-local cloud-config cloud-final
----

. Deregister from `scc`:
+
----
SUSEConnect -d; SUSEConnect --cleanup
----

. Do a cleanup of the SLE image for converting into a VMware template. As root, run:
+
----
rm /etc/machine-id /var/lib/zypp/AnonymousUniqueId \
/var/lib/systemd/random-seed /var/lib/dbus/machine-id \
/var/lib/wicked/*
----
. Clean up btrfs snapshots and create one with initial state:
+
----
snapper list
snapper delete <list_of_nums_of_unneeded_snapshots>
snapper create -d "Initial snapshot for caasp template" -t single
----
. Power down the VM. As root, run:
+
----
shutdown -h now
----

==== Creating the VMware Template

Now you can convert the VM into a template in VMware (or repeat this action block for each VM).

. In the vSphere WebUI, right-click on the VM and select menu:Template[Convert to Template].
Name it reasonably so you can later identify the template. The template will be created.

=== Deploying VMs from the Template

==== Terraform

. Find the {tf} template files for {soc} in `/usr/share/caasp/terraform/vmware` (which was installed as part of the management
pattern (`sudo zypper in patterns-caasp-Management`)).
Copy this folder to a location of your choice as the files need adjustment.
+
----
mkdir -p ~/caasp/deployment/
cp -r /usr/share/caasp/terraform/vmware/ ~/caasp/deployment/
cd ~/caasp/deployment/vmware/
----
. Once the files are copied, rename the `terraform.tfvars.example` file to
`terraform.tfvars`:
+
----
mv terraform.tfvars.example terraform.tfvars
----
. Edit the `terraform.tfvars` file and add/modify the following variables:
+
include::deployment-terraform-example.adoc[tag=tf_vmware]
. Enter the product key for your nodes in `~/caasp/deployment/vmware/registration.auto.tfvars`:
+
Substitute `CAASP_PRODUCT_KEY` for the code from <<registration_code>>.
+
[source,json]
----
# SUSE CaaSP Product Product Key
caasp_registry_code = "CAASP_PRODUCT_KEY"
----
+
This is required so all the deployed nodes can automatically register with {scc} and retrieve packages.

Once the files are adjusted, `terraform` needs to know about the `vSphere` server
and the login details for it; these can be exported as environment variables or
entered every time `terraform` is invoked.

Additionally, the `ssh-key` that is specified in the `tfvars` file must be added
to the keyring, so the machine running `skuba` can `ssh` into the machines:

----
export VSPHERE_SERVER="<server_address"
export VSPHERE_USER="<username>"
export VSPHERE_PASSWORD="<password>"
export VSPHERE_ALLOW_UNVERIFIED_SSL=true # In case you are using custom certificate for accessing vsphere API

ssh-add <path_to_private_ssh_key_from_tfvars>
----

Run Terraform to create the required machines for use with `skuba`:

----
terraform init
terraform plan
terraform apply
----

==== Setup by Hand
For each VM deployment, follow the {ay} installation method used for deployment on
bare metal machines as described in <<deployment_bare_metal>>.

[IMPORTANT]
====
Make sure to give each VM in VMware a clear name that shows its purpose in the cluster, for example

* `caasp-master-0`
* `caasp-worker-0`
* `caasp-worker-1`

You will need these names during bootstrapping of the cluster.
====
. Power on the newly created VMs.
. You need to know the FQDN/IP for each of the created VMs during the bootstrap process.
