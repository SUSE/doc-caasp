<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.1" xml:id="cha.admin.monitoring"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Monitoring</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>

 <sect1 xml:id="sec.admin.monitoring.cluster">
  <title>Cluster Monitoring</title>

  <para>
   There are three basic ways how you can monitor your cluster:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     by directly accessing the <emphasis>cAdvisor</emphasis> on
     <literal>http://<replaceable>WORKER NODE ADDRESS</replaceable>
     ;:4194/containers/</literal>. The <emphasis>cAdvisor</emphasis> runs on
     worker nodes by default.
    </para>
   </listitem>
   <listitem>
    <para>
     By using <emphasis>Heapster</emphasis>, for details refer to
     <xref linkend="sec.admin.monitoring.cluster..heapster"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     By using <emphasis>Grafana</emphasis>, for details refer to
     <xref linkend="sec.admin.monitoring.cluster..grafana"/>.
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="sec.admin.monitoring.cluster..heapster">
   <title>Monitoring with Heapster</title>
   <para>
    <emphasis>Heapster</emphasis> is a tool that collects and interprets
    various signals from your cluster. <emphasis>Heapster</emphasis>
    communicates directly with the <emphasis>cAdvisor</emphasis>. The signals
    from the cluster are then exported using REST endpoints.
   </para>
   <para>
    To deploy <emphasis>Heapster</emphasis>, run the following command:
   </para>
 <screen>&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/SUSE/caasp-services/master/contrib/addons/heapster/heapster.yaml</command></screen>
   <para>
    <emphasis>Heapster</emphasis> can store data in
    <emphasis>InfluxDB</emphasis>, which can be then used by other tools.
   </para>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.cluster..grafana">
   <title>Monitoring with Grafana</title>
   <para>
    <emphasis>Grafana</emphasis> is an analytics platform that processes data
    stored in <emphasis>InfluxDB</emphasis> and displays the data graphically.
    You can deploy <emphasis>Grafana</emphasis> by running the following
    commands:
   </para>
 <screen>&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/SUSE/caasp-services/master/contrib/addons/heapster/heapster.yaml</command>
&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml</command>
&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/kubernetes/heapster/release-1.3/deploy/kube-config/influxdb/grafana-deployment.yaml</command>
&prompt.user;<command>curl https://raw.githubusercontent.com/kubernetes/heapster/release-1.3/deploy/kube-config/influxdb/grafana-service.yaml -o grafana-service.yaml</command></screen>
   <para>
    Then open the file <filename>grafana-service.yaml</filename>:
   </para>
 <screen>&prompt.user;<command>vi grafana-service.yaml</command></screen>
   <para>
    In the file uncomment the line with the <literal>NodePort</literal> type.
   </para>
   <para>
    To finish the <emphasis>Grafana</emphasis> installation, apply the
    configuration by running:
   </para>
<screen>&prompt.root;<command>kubectl apply -f grafana-service.yaml</command></screen>
  </sect2>
 </sect1>

 <sect1 xml:id="sec.admin.monitoring.cluster.health">
  <title>Cluster Health Checking</title>
  <para>
   Although &kube; takes care of a lot of traditional deployment problems
   automatically, it is considered good practice to monitor the availability
   and health of your services and applications to react to problems should they
   go beyond the self-healing capabilities this is, however, beyond the scope of
   this document.
  </para>

  <para>
   This document is intended to give you an overview of points you should monitor
   to ensure correct functionality of the &productname; itself.
  </para>

  <note>
   <title>Upstream Documentation On Monitoring Details</title>
   <para>
    Instructions like how to set up <link xlink:href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/">Liveness and Readiness Probes</link>
    or how to <link xlink:href="https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/">Monitor individual Node health</link>
    can be found in the &kube; upstream documentation.
   </para>
  </note>

  <sect2 xml:id="sec.admin.monitoring.cluster.health.etcd">
   <title><literal>etcd</literal> Cluster Health</title>
   <para>
    - Check that all machines that have the `etcd` role on the cluster see the etcd cluster as healthy.
<screen>
docker exec -it $(docker ps | grep salt-master | awk '{print $1}') \
salt -G 'roles:etcd' \
cmd.run 'set -a; source /etc/sysconfig/etcdctl; etcdctl cluster-health'
    </screen>
   </para>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.cluster.health.components">
   <title>Running Components</title>
   <para>
    Check if the cluster has all required components running:
   </para>
   <screen>
kubectl cluster-info
      </screen>
      <para>
       You can optionally run <command>kubectl cluster-info dump</command> to obtain a much more detailed output
      </para>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.cluster.disk-usage">
   <title>Disk Usage</title>
   <para>
    It's good to also check that all machines are healthy in terms of free disk space from time to time, also when something fails:
   </para>

<screen>&prompt.user;docker exec -it $(docker ps | grep salt-master | awk '{print $1}') \
salt -P 'roles:(admin|kube-master|kube-minion)' \
cmd.run "df -h"
  </screen>
 </sect2>


  </sect1>
</chapter>
