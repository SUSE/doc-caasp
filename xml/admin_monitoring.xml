<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha.admin.monitoring"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Monitoring</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <sect1 xml:id="sec.admin.monitoring.cluster">
  <title>Cluster Monitoring</title>

  <para>
   There are three basic ways how you can monitor your cluster:
  </para>

  <itemizedlist>
   <listitem>
    <para>
     By directly accessing the <emphasis>cAdvisor</emphasis> on
     <literal>http://<replaceable>WORKER NODE
     ADDRESS</replaceable>:4194/containers/</literal>.
    </para>
    <para>
     The <emphasis>cAdvisor</emphasis> runs on worker nodes by default.
    </para>
   </listitem>
   <listitem>
    <para>
     By using <emphasis>Heapster</emphasis>, for details refer to
     <xref linkend="sec.admin.monitoring.cluster.heapster"/>.
    </para>
   </listitem>
   <listitem>
    <para>
     By using <emphasis>Grafana</emphasis>, for details refer to
     <xref linkend="sec.admin.monitoring.cluster.grafana"/>.
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="sec.admin.monitoring.cluster.heapster">
   <title>Monitoring with Heapster</title>
   <para>
    <emphasis>Heapster</emphasis> is a tool that collects and interprets
    various signals from your cluster. <emphasis>Heapster</emphasis>
    communicates directly with the <emphasis>cAdvisor</emphasis>. The signals
    from the cluster are then exported using REST endpoints.
   </para>
   <para>
    To deploy <emphasis>Heapster</emphasis>, run the following command:
   </para>
<screen>&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/SUSE/caasp-services/master/contrib/addons/heapster/heapster.yaml</command></screen>
   <para>
    <emphasis>Heapster</emphasis> can store data in
    <emphasis>InfluxDB</emphasis>, which can be then used by other tools.
   </para>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.cluster.grafana">
   <title>Monitoring with Grafana</title>
   <para>
    <emphasis>Grafana</emphasis> is an analytics platform that processes data
    stored in <emphasis>InfluxDB</emphasis> and displays the data graphically.
    You can deploy <emphasis>Grafana</emphasis> by running the following
    commands:
   </para>
<screen>&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/SUSE/caasp-services/master/contrib/addons/heapster/heapster.yaml</command>
&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/kubernetes/heapster/master/deploy/kube-config/influxdb/influxdb.yaml</command>
&prompt.user;<command>kubectl apply -f \
https://raw.githubusercontent.com/kubernetes/heapster/release-1.3/deploy/kube-config/influxdb/grafana-deployment.yaml</command>
&prompt.user;<command>curl https://raw.githubusercontent.com/kubernetes/heapster/release-1.3/deploy/kube-config/influxdb/grafana-service.yaml -o grafana-service.yaml</command></screen>
   <para>
    Then open the file <filename>grafana-service.yaml</filename>:
   </para>
<screen>&prompt.user;<command>vi grafana-service.yaml</command></screen>
   <para>
    In the file uncomment the line with the <literal>NodePort</literal> type.
   </para>
   <para>
    To finish the <emphasis>Grafana</emphasis> installation, apply the
    configuration by running:
   </para>
<screen>&prompt.root;<command>kubectl apply -f grafana-service.yaml</command></screen>
  </sect2>
 </sect1>
 <sect1 xml:id="sec.admin.monitoring.health">
  <title>Health Checking</title>

  <para>
   Although &kube; takes care of a lot of the traditional deployment problems
   with its self-healing capabilities, it is considered good practice to
   monitor the availability and health of your services and applications to
   react to problems should they go beyond these automated measures.
  </para>

  <para>
   A complete set of instructions on how to monitor and maintain the health of
   you cluster is, however, beyond the scope of this document.
  </para>

  <para>
   There are three levels of health checks.
  </para>

  <itemizedlist>
   <listitem>
    <para>
     Cluster
    </para>
   </listitem>
   <listitem>
    <para>
     Node
    </para>
   </listitem>
   <listitem>
    <para>
     Application / Service
    </para>
   </listitem>
  </itemizedlist>

  <sect2 xml:id="sec.admin.monitoring.health.cluster">
   <title>Cluster Health Checks</title>
   <para>
    The basic check if a cluster is working correctly is based on a few
    criteria:
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Are all services running as expected?
     </para>
    </listitem>
    <listitem>
     <para>
      Is there at least one &kube; master fully working? Even if the
      deployment is configured to be highly available, it's useful to know if
      <literal>kube-controller-manager</literal> is down on one of the machines.
     </para>
    </listitem>
   </itemizedlist>

   <note>
    <title>Understanding cluster health</title>
    <para>
     For further information consider reading
     <link xlink:href="https://kubernetes.io/docs/tasks/debug-application-cluster/debug-cluster/">&kube;:
     Troubleshoot Clusters</link>
    </para>
   </note>

   <sect3 xml:id="sec.admin.monitoring.health.cluster.kubernetes">
    <title>&kube; master</title>
    <para>
     All components in &kube; expose a <literal>/healthz</literal> endpoint. The
     expected (healthy) response is a <literal>200 HTTP</literal> and
     a response body containing <literal>ok</literal>.
    </para>
    <para>
     The minimal services for the master to work properly are:
    </para>
    <variablelist>
     <varlistentry>
      <term>kube-apiserver</term>
      <listitem>
      <para>
       The component that receives your requests from <command>kubectl</command>
       and from the rest of the &kube; components.
      </para>
      <para>
       Endpoint: <literal>https://<replaceable>MASTER NODE FQDN</replaceable>:6444/healthz</literal> (HTTPS)
      </para>
<screen>&prompt.user;<command>curl -i https://localhost:6444/healthz</command>
ok
      </screen>
     </listitem>
    </varlistentry>
    <varlistentry>
      <term>kube-controller-manager</term>
      <listitem>
      <para>
       The component that contains the control loop, driving current state to
       the desired state.
      </para>
      <para>
       Endpoint: <literal>http://<replaceable>MASTER NODE FQDN</replaceable>:10252/healthz</literal> (HTTP)
      </para>
<screen>&prompt.user;<command>curl -i http://localhost:10252/healthz</command>
ok
      </screen>
     </listitem>
    </varlistentry>
     <varlistentry>
      <term>kube-scheduler</term>
      <listitem>
      <para>
       The component that schedules workloads to nodes.
      </para>
      <para>
       Endpoint: <literal>http://<replaceable>MASTER NODE FQDN</replaceable>:10251/healthz</literal> (HTTP)
      </para>
<screen>&prompt.user;<command>curl -i http://localhost:10251/healthz</command>
ok
      </screen>
     </listitem>
    </varlistentry>
   </variablelist>

   <note>
    <title>High-Availability Environments</title>
    <para>
     In a HA environment you can monitor <literal>kube-apiserver</literal> on
     <literal>https://<replaceable>MASTER NODE LOADBALANCER</replaceable>:6443/healthz</literal>.
    </para>
    <para>
     If any master node is running correctly you will receive a valid response.
    </para>
    <para>
     This does, however, not mean that all master nodes necessarily work
     correctly. To ensure that all master nodes work properly the health checks
     must be repeated individually for each master node deployed.
    </para>
    <para>
     This endpoint will return a successful HTTP response if the cluster is
     operational; otherwise it will fail. It will for example check that it can
     access <literal>etcd</literal> too. This should not be used to infer that
     the overall cluster health is ideal. It will return a a successful response
     even when only minimal operational cluster health exists.
    </para>
    <para>
     To probe for full cluster health, you must perform individual health
     checking for all machines individually.
    </para>
   </note>
  </sect3>

   <sect3 xml:id="sec.admin.monitoring.cluster.health.etcd">
    <title><literal>etcd</literal> Cluster</title>
    <para>
     Check that all machines that have the <literal>etcd</literal> role on the cluster see the
     etcd cluster as healthy.
    </para>
<screen>&prompt.user;<command>docker exec -it $(docker ps | grep salt-master | awk '{print $1}') salt -G 'roles:etcd' \
cmd.run 'set -a; source /etc/sysconfig/etcdctl; etcdctl cluster-health'</command>

f69e7af2880f42d68dca26ca892cb945:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy
ab040b25c2584bc8904971c0acbb250f:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy
63008aabc75b471b9a1aa2f64e4d30eb:
    member af7ffa9bb1cb7c67 is healthy: got healthy result from https://caasp-master:2379
    member cc40a990d09b4705 is healthy: got healthy result from https://caasp-worker-1:2379
    member fe9b5ee9e1cc3cf7 is healthy: got healthy result from https://caasp-worker-2:2379
    cluster is healthy
   </screen>
   <para>
    More information on etcd cluster health can be found in <xref linkend="sec.admin.nodes.graceful_shutdown.etcd"/>.
   </para>
   </sect3>

   <sect3 xml:id="sec.admin.monitoring.cluster.health.components">
    <title>Running Components</title>
    <para>
     Check if the cluster has all required components running:
    </para>
<screen>&prompt.user;<command>kubectl cluster-info</command>

Kubernetes master is running at https://api.infra.caasp.local:6443
Dex is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/dex:dex/proxy
KubeDNS is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
Tiller is running at https://api.infra.caasp.local:6443/api/v1/namespaces/kube-system/services/tiller:tiller/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
    </screen>
    <para>
     You can optionally run <command>kubectl cluster-info dump</command> to
     obtain a much more detailed output
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.health.node">
   <title>Node Health Checks</title>
   <para>
    The basic check if a node is healthy consists of checking if
    <literal>kubelet</literal> and the CNI (Container Networking Interface) are
    working properly.
   </para>

   <sect3 xml:id="sec.admin.monitoring.health.node.kubelet">
    <title>Check <literal>kubelet</literal> health</title>
    <para>
     Is the <literal>kubelet</literal> up and working in this node?
    </para>
    <para>
     The <literal>kubelet</literal> has a port exposed <literal>10250</literal>
     on all machines; it's possible to perform an HTTP request to the endpoint
     to find out if the kubelet is healthy on that machine. The
     expected (healthy) response is a <literal>200 HTTP</literal> and
     a response body containing <literal>ok</literal>.
    </para>
    <para>
     Endpoint: <literal>https://<replaceable>NODE</replaceable>:10250/healthz</literal> (HTTPS)
    </para>
<screen>&prompt.user;<command>curl -i https://localhost:10250/healthz</command>
ok
    </screen>
   </sect3>

   <sect3 xml:id="sec.admin.monitoring.health.node.cni">
    <title>Check <literal>CNI</literal></title>
    <para>
     Is CNI (Container Networking Interface) working as expected in this node?
     If not, <literal>kube-dns</literal> can not start. Check if the
     <literal>kube-dns</literal> service is running.
    </para>
<screen>&prompt.user;<command>kubectl get deployments -n kube-system</command>
NAME            DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
dex             3         3         3            3           7d
kube-dns        3         3         3            3           7d
tiller-deploy   1         1         1            1           7d
    </screen>

    <para>
     If kube-dns is running and you are able to create pods then you can be certain
     that CNI and your CNI plugin are working correctly.
    </para>
    <para>
     There's also the
     <link xlink:href="https://kubernetes.io/docs/tasks/debug-application-cluster/monitor-node-health/">Monitor Node Health</link>
     check. This is a <literal>DaemonSet</literal> that runs on every node, and
     reports to the <literal>apiserver</literal> back as
     <literal>NodeCondition</literal> and <literal>Events</literal>.
    </para>
   </sect3>
   </sect2>


  <sect2 xml:id="sec.admin.monitoring.health.service">
   <title>Service/Application Health Checks</title>
   <para>
    If the deployed services contain a health endpoint, or if they contain an
    endpoint that can be used to determine if the service is up, you can use
    <literal>livenessProbes</literal> and/or <literal>readinessProbes</literal>.
   </para>
   <note>
    <title>Health check endpoints vs. functional endpoints</title>
    <para>
     A proper health check is always preferred if designed correctly.
    </para>
    <para>
     Despite the fact that any endpoint could potentially be used to infer if
     your application is up, a specific health endpoint in your application is
     preferred. Such an endpoint will only respond affirmatively when all your
     setup code on the server has finished and the application is running in a
     desired state.
    </para>
   </note>

   <para>
    <literal>livenessProbes</literal> and <literal>readinessProbes</literal>
    share configuration options and probe types.
   </para>

   <variablelist>
    <varlistentry>
     <term>initialDelaySeconds</term>
     <listitem>
      <para>
       Number of seconds to wait before performing the very first liveness
       probe.
      </para>
     </listitem>
    </varlistentry>
    <varlistentry>
     <term>periodSeconds</term>
     <listitem>
      <para>
       Number of seconds that the kubelet should wait between liveness probes.
      </para>
     </listitem>
    </varlistentry>
   </variablelist>

    <variablelist>
     <varlistentry>
      <term>successThreshold</term>
     <listitem>
      <para>
        Number of minimum consecutive successes for the probe to be considered
        successful (Default: 1).
      </para>
     </listitem>
    </varlistentry>
     <varlistentry>
      <term>failureThreshold</term>
     <listitem>
      <para>
        Number of times this probe is allowed to fail in order to assume that
        the service is not responding (Default: 3).
      </para>
     </listitem>
    </varlistentry>
     <varlistentry>
      <term>timeoutSeconds</term>
     <listitem>
      <para>
       Number of seconds after which the probe times out (Default: 1).
      </para>
     </listitem>
    </varlistentry>
   </variablelist>
   <para>
    There are different options for the liveness probe to check:
   </para>
   <variablelist>
    <varlistentry>
     <term>Command</term>
     <listitem>
     <para>
      A command executed within a container; a retcode of 0 means success.
     </para>
      <para>
       All other return codes mean failure.
     </para>
    </listitem>
    </varlistentry>
    <varlistentry>
     <term>TCP</term>
     <listitem>
     <para>
      If a TCP connection can be established is considered success.
     </para>
    </listitem>
    </varlistentry>
    <varlistentry>
     <term>HTTP</term>
     <listitem>
     <para>
      Any HTTP response between <literal>200</literal> and <literal>400</literal>
      indicates success.
     </para>
    </listitem>
    </varlistentry>
   </variablelist>

   <sect3 xml:id="sec.admin.monitoring.health.service.livenessprobe">
    <title>livenessProbe</title>
    <para>
     <link xlink:href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/">livenessProbes</link>
     are used to detect running but misbehaving pods/a service that
     might be running (the process didn't die), but that is not responding as
     expected.
    </para>
    <para>
     Probes are executed by each <literal>kubelet</literal> against the pods that define them
     and that are running in that specific node.
    </para>
    <para>
     When a <literal>livenessProbe</literal> fails, &kube; will automatically restart the
     pod and increase the <literal>RESTARTS</literal> count for that pod.
    </para>
    <para>
     These probes will be executed every <literal>periodSeconds</literal> starting from
     <literal>initialDelaySeconds</literal>.
    </para>



   </sect3>
   <sect3 xml:id="sec.admin.monitoring.health.service.readinessprobe">
    <title>readinessProbe</title>
    <para>
     <link xlink:href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/#define-readiness-probes">readinessProbes</link>
     are used to wait for processes that take some time to start. Despite
     the container running, it might be performing some time consuming
     initializatoin operations. During this time, you don't want &kube; to route
     traffic to that specific pod; also, you don't want that container to be
     restarted because it will appear unresponsive.
    </para>
    <para>
     These probes will be executed every <literal>periodSeconds</literal>
     starting from <literal>initialDelaySeconds</literal> until the service is ready.
    </para>
    <para>
     They support the same kind of probes as the <literal>livenessProbe</literal>
    </para>

    <para>
     Both probe types can be used at the same time. The
     <literal>livenessProbe</literal> will ensure that if a service is running
     yet misbehaving, it will be restarted, and <literal>readinessProbe</literal>
     will ensure that &kube; won't route traffic to that specific pod until it's
     considered to be fully functional and running.
    </para>
   </sect3>
  </sect2>

  <sect2 xml:id="sec.admin.monitoring.health.general">
   <title>General Health Checks</title>
   <para>
    It is advisable to apply other best practices from system administration
    to your monitoring and health checking approach. These steps are not
    specific to &productname; and are beyond the scope of this document. To
    simplify performing tasks like disk usage checks, you can use <literal>salt</literal>.
    For more information see: <xref linkend="sec.admin.salt"/>
   </para>
  </sect2>
 </sect1>
</chapter>
