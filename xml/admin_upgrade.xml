<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha.admin.upgrade"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Upgrading &productname;</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  As &productname; is constantly developed and improved, new versions get
  released. You are strongly advised to upgrade to a supported release. These
  upgrades may involve manual intervention.
 </para>
 <important>
  <title>Service Window Required</title>
  <para>
   Upgrades may take some time, during which services may be degraded in
   performance or completely unavailable. Please make sure to plan a service
   window.
  </para>
 </important>
 <procedure xml:id="pro.admin.upgrade.procedure">
  <title>General Upgrade Procedure</title>
  <step>
   <para>
    Upgrade the &admin_node;.
   </para>
  </step>
  <step>
   <para>
    Manually perform additional upgrade steps of the &admin_node;. These steps
    are version-specific and described in the following chapters.
   </para>
  </step>
  <step>
   <para>
    Upgrade the cluster nodes through &dashboard;.
   </para>
  </step>
 </procedure>

 <sect1 xml:id="sec.deploy.upgrade.caasp2">
  <title>Upgrading from &productname; 2</title>
    
  <sect2 xml:id="sec.deploy.upgrade.caasp2.prereq">
   <title>Ensure All &productname; v2 Updates Are Installed</title>
   <para>
    Before you start the upgrade procedure to &productname; v3, you must ensure
    that all your nodes are running on the latest v2 updates. You can check the
    <filename>SUSEConnect</filename> package version to see if you are up to date.
    To do so you will run a <command>salt</command> command to display the
    package version installed on each node.
   </para>
   
   <screen>
&prompt.user;<command>docker exec -i  $(docker ps | grep salt-master | awk '{print $1}') \
salt --batch 10 -P "roles:(admin|kube-(master|minion))" \
cmd.run "rpm -q SUSEConnect"</command>

Executing run on ['12cda3c374144d74804298bdee4d686c',
                  '9b6d8d28393045c0914c959d0a5c0e33',
                  '73b92dd7816147058c3d0fbb67fb18f9',
                  'admin']
admin:
    SUSEConnect-0.3.11-3.15.1.x86_64
jid:
    20180809103558881056
retcode:
    0
73b92dd7816147058c3d0fbb67fb18f9:
    SUSEConnect-0.3.11-3.15.1.x86_64
jid:
    20180809103558881056
retcode:
    0
9b6d8d28393045c0914c959d0a5c0e33:
    SUSEConnect-0.3.11-3.15.1.x86_64
jid:
    20180809103558881056
retcode:
    0
12cda3c374144d74804298bdee4d686c:
    SUSEConnect-0.3.11-3.15.1.x86_64
jid:
    20180809103558881056
retcode:
    0
   </screen>
   
   <para>
    If the package version is <literal>0.3.11-3.15.1</literal> (or higher) you
    have the latest updates from the v2 channel installed.
   </para>
   </sect2>
   
   <sect2 xml:id="sec.deploy.upgrade.caasp2.timer">
    <title>Disable Automatic <literal>transactional-update</literal></title>
    <para>
    To begin with the upgrade procedure, you first must disable the automatic
    transactional update mechanism to avoid conflicts. To do so you must run a
    <command>salt</command> across the nodes to disable the 
    <literal>transactional-update.timer</literal>.
    </para>
    <screen>
&prompt.user;<command>docker exec -i $(docker ps | grep salt-master | awk '{print $1}') \
salt --batch 10 -P "roles:(admin|kube-(master|minion))" \
cmd.run "systemctl disable --now transactional-update.timer"</command>

Executing run on ['5f6688bbeac94d2ab5c4330dc7043fb2',
                  'c3afd049edbe43afb4e2e5913a88291b',
                  '5bf346291a18406290886c2e2f7c3e3f',
                  'admin']

5bf346291a18406290886c2e2f7c3e3f:
    Removed symlink /etc/systemd/system/timers.target.wants/transactional-update.timer.
jid:
    20180807122220543037
retcode:
    0
admin:
    Removed symlink /etc/systemd/system/timers.target.wants/transactional-update.timer.
jid:
    20180807122220543037
retcode:
    0
c3afd049edbe43afb4e2e5913a88291b:
    Removed symlink /etc/systemd/system/timers.target.wants/transactional-update.timer.
jid:
    20180807122220543037
retcode:
    0
5f6688bbeac94d2ab5c4330dc7043fb2:
    Removed symlink /etc/systemd/system/timers.target.wants/transactional-update.timer.
jid:
    20180807122220543037
retcode:
    0
    </screen>
    <important>
    <para>
     If you use &smtool; or &susemgr; for mirroring channels: Mirror the v3 channels on your server.
    </para>
   </important>
   </sect2>
   
   <sect2 xml:id="sec.deploy.upgrade.caasp2.upgrade">
    <title>Performing The Upgrade Procedure</title>
    <para>
     In the next step you must run the update command across your nodes.
    </para>
    <note>
     <title>Batch size for upgrade</title>
     <para>
      In this example we have limited the number of nodes this step will be 
      performed on to <literal>10 nodes</literal> at a time.
     </para>
      
      <para>
      This is a precaution to avoid problems on slower network connections.
      If you are performing this step on a high bandwidth connection (for 
      example from within the same datacenter as the cluster), you can raise the
      number of nodes by replacing the value for the (<literal>--batch</literal>)
      parameter. It is highly recommended not to change this setting.
     </para>
    </note>
    <screen>
&prompt.user;<command>docker exec -i $(docker ps | grep salt-master | awk '{print $1}') \
salt --batch <replaceable>10</replaceable> -P "roles:(admin|kube-(master|minion))" \
cmd.run "transactional-update salt migration -n" \
| tee transactional-update-migration.log</command>

Executing run on ['5f6688bbeac94d2ab5c4330dc7043fb2',
                  'c3afd049edbe43afb4e2e5913a88291b',
                  '5bf346291a18406290886c2e2f7c3e3f',
                  'admin']

5bf346291a18406290886c2e2f7c3e3f:
    
    
    Executing 'zypper --root /tmp/tmp.vbaqUwrLIh --non-interactive  refresh'
    
    Retrieving repository 'SUSE-CAASP-ALL-Pool' metadata [...done]
    Building repository 'SUSE-CAASP-ALL-Pool' cache [....done]
    Retrieving repository 'SUSE-CAASP-ALL-Updates' metadata [....done]
    Building repository 'SUSE-CAASP-ALL-Updates' cache [....done]
    All repositories have been refreshed.
    Upgrading product SUSE CaaS Platform 3.0 x86_64.

[ SNIP ... ]

    done
jid:
    20180807122253512832
retcode:
    0
    </screen>
    <para>
     During the procedure the nodes will be switched to the new release channel
     for v3, available updates are downloaded and installed, services and 
     applications are reconfigured and brought up in a orderly fashion.
    </para>
    <para>
     This operation will produce a lot of output for each node. The entire output
     is mirrored to a log file <filename>transactional-update-migration.log</filename>
     to the current working directory. This log file can be very helpful should
     any of the update operations fail.
    </para>
   </sect2>
   
   <sect2 xml:id="sec.deploy.upgrade.caasp2.reboot">
    <title>Reboot cluster nodes from &dashboard;</title>
    <para>
     To complete the procedure, you must reboot the cluster nodes. To do this 
     properly, use &dashboard; to restart the nodes.
    </para>
    <procedure>
     <step>
      <para>
       Log in to &dashboard;.
      </para>
     </step>
     <step>
      <para>
       Update the Admin node as described in 
       <xref linkend="sec.admin.transactional-updates.installation" />.
      </para>
     </step>
     <step>
      <para>
       Update the remaining nodes as described in 
       <xref linkend="sec.admin.transactional-updates.installation" />.
      </para>
     </step>
    </procedure>
   </sect2>
  
  <sect2 xml:id="sec.deploy.upgrade.caasp2.troubleshooting">
   <title>Troubleshooting</title>
   <para>
    In case the upgrade fails, please perform the support data collection by 
    running <command>supportconfig</command> on the affected nodes. Provide the 
    resulting files including the <filename>transactional-update-migration.log</filename>
    to SUSE Support.
   </para>
  </sect2>
  
 </sect1>
 
</chapter>
