<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.0" xml:id="cha-deploy-nodes"
 xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Installing and Configuring Nodes</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>
 <para>
  This chapter details the procedures for installing the &admin_node;,
  master nodes and worker nodes. Make sure that you prepared the
  installation according to <xref
  linkend="cha-deployment-preparation" />.
 </para>
 <sect1 xml:id="sec-deploy-nodes-admin-install">
  <title>Installing the &Admin_Node;</title>
  <para>
   The procedure for installing the &admin_node; is identical whether or not
   you use &ay; for the rest of the cluster.
  </para>
  <procedure xml:id="pro-deploy-nodes-admin-install">
   <step>
    <para>
     Connect or insert the &productname; installation media, then reboot the
     computer to start the installation program. On machines with a
     traditional BIOS, you will see the graphical boot screen shown below.
     The boot screen on machines equipped with UEFI is slightly different.
    </para>
    <para>
     SecureBoot on UEFI machines <emphasis>is</emphasis> supported.
    </para>
    <para>
     Use <keycap>F2</keycap> to change the language for the installer. A
     corresponding keyboard layout is chosen automatically. See
     <link
      xlink:href="https://www.suse.com/documentation/sles-12/book_sle_deployment/data/sec_i_yast2_startup.html"
     />
     for more information about changing boot options.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="install_boot.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="install_boot.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
   </step>
   <step>
    <para>
     Select <guimenu>Installation</guimenu> on the boot screen, then press
     <keycap
      function="enter"
     />. This boots the system and
     loads the &productname; installer.
    </para>
   </step>
   <step>
<!-- <para>
      Read the License Agreement. It is presented in the language you have
      chosen on the boot screen. <guimenu>License Translations</guimenu> are
      available. You need to accept the agreement by checking <guimenu>I Agree
      to the License Terms</guimenu> to install &productname;. Proceed with
      <guimenu>Next</guimenu>.
      </para>  -->
    <para>
     Configure the following mandatory settings on the <guimenu>Installation
     Overview</guimenu> screen.
    </para>
    <note>
     <title>Help and Release Notes</title>
     <para>
      From this point on, a brief help document and the Release Notes can be
      viewed from any screen during the installation process by selecting
      <guimenu>Help</guimenu> or <guimenu>Release Notes</guimenu>
      respectively.
     </para>
    </note>
    <variablelist>
     <varlistentry>
      <term>Keyboard Layout</term>
      <listitem>
       <para>
        The <guimenu>Keyboard Layout</guimenu> is initialized with the
        language settings you have chosen on the boot screen. Change it here,
        if necessary.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Password for &rootuser;</term>
      <listitem>
       <para>
        Type a password for the system administrator account (called the
        &rootuser; user) and confirm it.
       </para>
       <warning>
        <title>Do not forget the &rootuser; Password</title>
        <para>
         You must not lose the &rootuser; password! After you enter it here,
         the password cannot be retrieved. For more information, see
         <link
          xlink:href="https://www.suse.com/documentation/sles-12/book_sle_deployment/data/sec_i_yast2_user_root.html"
         />.
        </para>
       </warning>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Registration Code or SMT Server URL</term>
      <listitem>
       <para>
        Enter the <guimenu>Registration Code or SMT Server
        URL</guimenu>. SMT Server URLs should use
        <literal>https</literal> or <literal>http</literal>; other
        protocols are not supported. Fill this field to enable
        installing current updates during the installation process.
        Alternatively, the machine can be registered at the &scc; or a
        &smt; server at any later point in time with
        <command>SUSEConnect</command>. For details about registering
        with <command>SUSEConnect</command> and using an authenticated
        proxy server for registration, see <xref
        linkend="sec-configuration-suseconnect" />.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>System Role</term>
      <listitem>
       <para>
        From the <guimenu>System Role</guimenu> menu, choose <guimenu>
        Administration Node (Dashboard)</guimenu>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>NTP Servers</term>
      <listitem>
       <para>
        Enter the host names or IP addresses of one or more <guimenu>NTP
        Servers</guimenu> for the node, separated by colons or white space. A
        single time server is sufficient, but for optimal precision and
        reliability, nodes should use at least three.
       </para>
       <para>
        We recommend providing a dedicated NTP server from your local network.
       </para>
       <para>
        For more information about <literal>NTP</literal>, refer to
        <link
         xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_netz_xntp.html"
        />
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="install_overview_admin.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="install_overview_admin.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
    <para>
     Optionally, you can customize the following settings. If you do not make
     any changes, defaults are used. A brief summary of the settings is
     displayed below the respective settings option.
    </para>
    <variablelist>
     <varlistentry>
      <term>Partitioning</term>
      <listitem>
       <para>
        Review the partition setup proposed by the system and change it if
        necessary. You have the following options:
       </para>
       <variablelist>
        <varlistentry>
         <term>Select a hard disk</term>
         <listitem>
          <para>
           Select a disk on to which to install &productname; with the
           recommended partitioning scheme.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term><guimenu>Custom Partitioning (for Experts)</guimenu></term>
         <listitem>
          <para>
           Opens the <guimenu>Expert Partitioner</guimenu> described in
           <link
            xlink:href="https://www.suse.com/documentation/sles-12/book_sle_deployment/data/sec_yast2_i_y2_part_expert.html"
           />.
          </para>
          <warning>
           <title>For Experts only</title>
           <para>
            As the name suggests, the <guimenu>Expert Partitioner</guimenu>
            is for experts only. Custom partitioning schemes that do not meet
            the requirements of &productname; are not supported.
           </para>
           <itemizedlist>
            <title>Requirements for custom partitioning schemes</title>
            <listitem>
             <para>
              &productname; only supports the &btrfs; file system with
              OverlayFS. A read-only &btrfs; file system is used for the root
              file system, which enables transactional updates.
             </para>
            </listitem>
            <listitem>
             <para>
              For snapshots, partitions should have a capacity of at least 11
              GB.
             </para>
            </listitem>
            <listitem>
             <para>
              Depending on the number and size of your containers, you will
              need sufficient space under the <filename>/var</filename> mount
              point.
             </para>
            </listitem>
           </itemizedlist>
          </warning>
         </listitem>
        </varlistentry>
       </variablelist>
       <para>
        To accept the proposed setup without any changes, choose
        <guimenu>Next</guimenu> to proceed.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Booting</term>
      <listitem>
       <para>
        This section shows the boot loader configuration. Changing the
        defaults is only recommended if really needed. For details, refer to
        <link
         xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/cha_grub2.html"
        />.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Network Configuration</term>
      <listitem>
       <para>
        If the network could not be configured automatically while starting
        the installation system, you should manually configure the
        <guimenu>Network Settings</guimenu>. Please make sure at least one
        network interface is connected to the Internet in order to register
        your product.
       </para>
       <para>
        By default, the installer requests a host name from the DHCP server.
        If you set a custom name in the <guimenu>Hostname/DNS</guimenu> tab,
        make sure that it is unique.
       </para>
       <para>
        For more information on configuring network connections, refer to
        <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_admin/data/sec_basicnet_yast.html"/>.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>&kdump;</term>
      <listitem>
       <para>
        &kdump; saves the memory image (<quote>core dump</quote>) to the file
        system in case the kernel crashes. This enables you to find the cause
        of the crash by debugging the dump file. For more information, see
        <link xlink:href="https://www.suse.com/documentation/sles-12/book_sle_tuning/data/cha_tuning_kdump_basic.html"/> .
       </para>
       <warning>
        <title>&kdump; with large amounts of RAM</title>
        <para>
         If you have a system with large amounts of RAM or a small hard
         drive, core dumps may not be able to fit on the disk. If the
         installer warns you about this, there are two options:
        </para>
        <orderedlist>
         <listitem>
          <para>
           Enter the <guimenu>Expert Partitioner</guimenu> and increase the
           size of the root partition so that it can accommodate the size of
           the core dump. In this case, you will need to decrease the size of
           the data partition accordingly. Remember to keep all other
           parameters of the partitioning (e.g. the root file system, mount
           point of data partition) when doing these changes.
          </para>
         </listitem>
         <listitem>
          <para>
           Disable &kdump; completely.
          </para>
         </listitem>
        </orderedlist>
       </warning>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>System Information</term>
      <listitem>
       <para>
        View detailed hardware information by clicking <guimenu>System
        Information</guimenu>. In this screen you can also change
        <guimenu>Kernel Settings</guimenu>. See
        <link
         xlink:href="https://www.suse.com/documentation/sles-12/book_sle_tuning/data/cha_tuning_io.html"
        />
        for more information.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
    <para>
     Proceed with <guimenu>Next</guimenu>.
    </para>
    <tip>
     <title>Installing Product Patches at Installation Time</title>
     <para>
      If &productname; has been successfully registered at the &scc;, you are
      asked whether to install the latest available online updates during the
      installation. If you choose <guimenu>Yes</guimenu>, the system will be
      installed with the most current packages without having to apply the
      updates after installation. Activating this option is recommended.
     </para>
    </tip>
   </step>
   <step>
    <para>
     After you have finalized the system configuration on the
     <guimenu>Installation Overview</guimenu> screen, click
     <guimenu>Install</guimenu>. Up to this point no changes have been made
     to your system.
    </para>
    <para>
     Click <guimenu>Install</guimenu> a second time to start the installation
     process.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="install_confirm.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="install_confirm.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
   </step>
   <step>
    <para>
     During the installation, the progress is shown in detail on the
     <guimenu>Details</guimenu> tab.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="install_perform.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="install_perform.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
   </step>
   <step>
    <para>
     After the installation routine has finished, the computer will reboot
     into the installed system.
    </para>
   </step>
  </procedure>
 </sect1>

 <sect1 xml:id="sec-deploy-nodes-admin-install-cli">
  <title>Installing the &Admin_Node; with Command Line Interface</title>
  <important>
   <title>Do not use this for datacenter installations</title>
   <para>
    This procedure is intended to be used with public cloud
    installations only.
   </para>
  </important>
  <para>
   Use SSH to log into the admin node and run the
   <command>caasp-admin-setup</command> executable as the
   <literal>root</literal>user.
  </para>
  <para>
   By default the <command>caasp-admin-setup</command> executable operates in
   <literal>wizard</literal> mode, walking you through the necessary steps.
   During this process your &scc; credentials will be requested. Registration
   with &scc; can be skipped. If this step is skipped during setup the admin node
   and the cluster nodes will not receive any updates. While registration to
   &scc; can be performed after the initial setup with
   <literal>SUSEConnect</literal>, performing the registration during setup has
   the advantage that cluster nodes will automatically be registered with &scc;
   as well. If you prefer not to run the <literal>wizard</literal>, use
   <command>caasp-admin-setup --help</command> to obtain a list of the
   available command line arguments.
  </para>
  <para>
   Once the <literal>caasp-admin-setup</literal> process is complete all
   &productname; containers will be launched on the admin node instance. Use
   your web browser to access the Velum dashboard via <literal>https</literal>.
   If you did not provide your own certificate, a certificate was generated for
   you and the fingerprint was written to the terminal in which
   <command>caasp-admin-setup</command> was executed. You can compare this
   fingerprint in your browser to establish the chain of trust.
  </para>
  <sect2>
   <title><command>caasp-admin-setup</command> Details</title>
   <para>
    The general purpose of <command>caasp-admin-setup</command> is to collect
    all information needed to successfully start the &productname; containers.
   </para>
   <para>
    When <command>caasp-admin-setup</command> is executed it determines which
    cluster node image to use according to the cloud framework. For this
    operation to succeed outgoing traffic on port <literal>443</literal> to the
    Internet must be permitted. The code will access the <literal>Public Cloud
    Information Tracker</literal> service operated by SUSE. This service
    provides information about all images ever released to the Public Cloud by
    SUSE. The latest available cluster node image for this version of
    &productname; will be used. This initial outreach and image filtering
    introduces a small startup delay before the command line options are
    processed or the wizard mode starts.
   </para>
   <para>
    When all information is collected, accept your selections/input with
    <literal>y</literal> to complete the initial setup.
   </para>
  </sect2>
  <sect2>
   <title>Providing SSL Certificate and Key</title>
   <para>
    You may choose to supply your own SSL certificate and key for initial
    access the dashboard, with the <literal>--ssl-crt</literal> and
    <literal>--ssl-key</literal> options or by answering the question
    <quote>Would you like to use your own certificate from a known (public
    or self signed) Certificate Authority?</quote> with
    <literal>y</literal>.
   </para>
   <para>
    In order to use your own SSL certificate and key you must upload the files
    to the admin node into a location of your choice. This location is then
    provided to the setup code. For example, if your certificate is called
    <filename>my-velum.crt</filename> and you uploaded it to
    <filename>/tmp</filename> then the <command>caasp-admin-setup</command>
    code expects <filename>/tmp/my-velum.crt</filename> as the location for
    the SSL certificate. The same concept applies to the SSL key. The
    certificate and key will be placed in the appropriate locations on the
    admin node.
   </para>
  </sect2>
  <sect2>
   <title>Velum Administrator Credentials</title>
   <para>
    Velum is the name of the administrative dashboard web interface. The setup
    code will ask for an e-mail address and a password if not supplied with
    the <literal>--admin-email</literal> and
    <literal>--admin-password</literal> arguments. These are the
    administrative credentials to log into the Velum dashboard. The e-mail
    used does not have to be an e-mail associated with your &scc; account.
    Please do not forget the values you enter, as they cannot be recovered.
   </para>
  </sect2>
  <sect2>
   <title>Registering with &scc;</title>
   <para>
    To register all cluster nodes with &scc;, provide your e-mail
    address and the registration code. The registration process
    requires access to the Internet on port 443. Alternatively you may
    use the <literal>--reg-email</literal> and
    <literal>--reg-code</literal> arguments. Registration with &scc; is
    optional. However, without registration the system will not receive
    any updates unless specifically setup to receive updates via a
    different route such as a private &smt; server. Registration after
    the initial setup also requires an explicit registration of each
    node in the cluster.
   </para>
   <para>
    For registering your nodes after the installation, refer to
    <xref linkend="sec-configuration-suseconnect" />.
   </para>
  </sect2>
 </sect1>

 <sect1 xml:id="sec-deploy-nodes-admin-configuration">
  <title>Configuring the &Admin_Node;</title>
  <para>
   Before installing the other nodes, it is necessary to configure the
   &admin_node;.
  </para>
  <procedure xml:id="pro-deploy-install-iso-config">
   <step>
    <para>
     After the &admin_node; has finished booting and you see the login
     prompt, point a web browser to:
    </para>
    <para>
     <uri>https://<replaceable>caasp-admin.&exampledomain;</replaceable>
     </uri>
    </para>
    <para>
     ... where <literal>caasp-admin.&exampledomain;</literal> is the host
     name or IP address of the &admin_node;. The host name and IP address are
     both shown on the &admin_node; console, above the login prompt.
    </para>
<!-- cwickert 2017-07-23 TODO: We don't really need this image, do we? -->
<!-- <informalfigure>
     <mediaobject>
     <imageobject role="fo">
     <imagedata fileref="velum_login.png" width="100%"/>
     </imageobject>
     <imageobject role="html">
     <imagedata fileref="velum_login.png" width="100%"/>
     </imageobject>
     </mediaobject>
     </informalfigure> -->
   </step>
   <step>
    <para>
     To create an Administrator account, click <guimenu>Create an
     account</guimenu> and provide an e-mail address and a password. Confirm
     the password and click <guimenu>Create Admin</guimenu>. You will be
     logged into the dashboard automatically.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="velum_register.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="velum_register.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
   </step>
   <step>
    <para>
     Fill in the values <guimenu>Internal Dashboard Location</guimenu>.
     If necessary, configure the other settings.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="velum_setup1.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="velum_setup1.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
    <note>
     <title>
      Host Name, FQDN or IP Address
     </title>
     <para>
      Generally, FQDNs are preferable to host names.
     </para>
     <para>For test deployments, you can use IP addresses instead of names for
      both the dashboard and API server, but this is not recommended for
      use in production.
     </para>
    </note>
    <variablelist>
     <varlistentry>
      <term>Internal Dashboard Location</term>
      <listitem>
       <para>
        FQDN or IP of the node running the &dashboard; dashboard (reachable
        from inside the cluster).
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Install Tiller (Helm's Server Component)</term>
      <listitem>
       <para>
        If you intend to deploy &scf; on &productname;, or any other software
        that is installed with &helm; (the &kube; package manager), check the
        box to install &tiller;.
<!-- (See <xref linkend="installing-helm"/>.) -->
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Overlay network settings</term>
      <listitem>
       <para>
        Describes the settings used by <literal>flannel</literal> to create
        the overlay network used by all the &kube; pods and services. With
        this change, the default settings are exposed to the user for fine
        tuning. The most common reason to change them is to avoid clashes
        between the default subnetwork we picked up and an already
        existing one.
       </para>
       <para>
        Networks are described in <link xlink:href="https://searchnetworking.techtarget.com/definition/CIDR">CIDR notation</link>.
       </para>
       <informalfigure>
        <mediaobject>
         <imageobject role="fo">
          <imagedata fileref="velum_overlay_net.png" width="100%"/>
         </imageobject>
         <imageobject role="html">
          <imagedata fileref="velum_overlay_net.png" width="100%"/>
         </imageobject>
        </mediaobject>
       </informalfigure>
       <warning>
        <title>Adjust overlay network to avoid collision with existing services</title>
        <para>
         Per default the overlay network reserves a <literal>/13</literal>
         subnet and reserves a <literal>/23</literal> slice for each node.
        </para>
        <para>
         The overlay network settings have to be verified and adjusted so that
         they do not collide with any services / addresses in the infrastructure
         that potentially need to be reached from any node or
         service running within the &productname; cluster.
        </para>
        <para>
         For example, an oracle database is running on <literal>172.16.4.5</literal>
         in the existing infrastructure and a pod in the cluster needs to
         contact that database. Then, the defaults be adjusted to provide a
         different overlay network. Another example would be an NFS server or
         a SES/Ceph cluster running anywhere in the network
         <literal>172.16.0.0/13</literal> and where persistent storage access
         of the CaaSP cluster should be hosted on.
        </para>
        <para>
         If you need to adjust the overlay network because it collides with an
         existing network, you must also manually adjust the container bridge
         network on the &admin_node;. To do so, modify the
         <filename>/etc/docker/daemon.json</filename> file with the desired
         network specification. For example:
        </para>
<screen>
{
  "bip": "172.26.0.1/16"
}
        </screen>
        <para>
         You must then restart the container service.
        </para>
<screen>&prompt.root;<command>systemctl restart docker</command></screen>
       </warning>
       <variablelist>
        <varlistentry>
         <term>Cluster CIDR</term>
         <listitem>
          <para>
           Classless Inter-Domain Routing subnet size used for the cluster
           (Default: <literal>/13</literal>)
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Cluster CIDR (lower bound)</term>
         <listitem>
          <para>
           Lower boundary for CIDR notation
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Cluster CIDR (upper bound)</term>
         <listitem>
          <para>
           Upper boundary for CIDR notation
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Node allocation size (CIDR length per worker node)</term>
         <listitem>
          <para>
           Length of CIDR notation length per worker node in Bits
           (Default: <literal>23</literal>)
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Services CIDR</term>
         <listitem>
          <para>
           Classless Inter-Domain Routing subnet size used for services
           (Default: <literal>/16</literal>)
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>API IP address</term>
         <listitem>
          <para>
           IP address in the CIDR network for the &kube; API
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>DNS IP address</term>
         <listitem>
          <para>
           IP address in the CIDR network for the DNS service
          </para>
         </listitem>
        </varlistentry>
        </variablelist>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Proxy Settings</term>
      <listitem>
       <para>
        If enabled, you can set proxy servers for <literal>HTTP</literal> and
        <literal>HTTPS</literal>. You may also configure exceptions and
        choose whether to apply the settings only to the container engine or
        to all processes running on the cluster nodes.
       </para>
       <informalfigure>
        <mediaobject>
         <imageobject role="fo">
          <imagedata fileref="velum_proxy_net.png" width="100%"/>
         </imageobject>
         <imageobject role="html">
          <imagedata fileref="velum_proxy_net.png" width="100%"/>
         </imageobject>
        </mediaobject>
       </informalfigure>
       <variablelist>
        <varlistentry>
         <term>HTTP Proxy</term>
         <listitem>
          <para>
           HTTP Proxy to be used.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>HTTPS Proxy</term>
         <listitem>
          <para>
           HTTPS Proxy to be used.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>No-proxy</term>
         <listitem>
          <para>
           Comma separated list of hostnames/IP addresses whose traffic should
           not be routed through the configured proxy.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Use proxy systemwide</term>
         <listitem>
          <para>
           Select if the proxy settings will be applied for the
           <guimenu>Container engine only</guimenu> or for the
           <guimenu>Entire node</guimenu> communication.
          </para>
         </listitem>
        </varlistentry>
        </variablelist>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>SUSE registry mirror</term>
      <listitem>
       <para>
        Configure a mirror for the SUSE container registry.
       </para>
       <informalfigure>
        <mediaobject>
         <imageobject role="fo">
          <imagedata fileref="velum_registry_mirror.png" width="100%"/>
         </imageobject>
         <imageobject role="html">
          <imagedata fileref="velum_registry_mirror.png" width="100%"/>
         </imageobject>
        </mediaobject>
       </informalfigure>
       <variablelist>
        <varlistentry>
         <term>URL</term>
         <listitem>
          <para>
           URL where the local registry mirror can be reached.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Certificate</term>
         <listitem>
          <para>
           Select <guimenu>No/Yes</guimenu> if you wish to provide the
           certificate used to protect your registry mirror. Copy the body of
           the certificate in the text field.
          </para>
         </listitem>
        </varlistentry>
        </variablelist>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Cloud provider integration</term>
      <listitem>
       <para>
        Cloud provider integration enables you to deploy &productname; on
        &ostack;/&soc;.
       </para>
       <informalfigure>
        <mediaobject>
         <imageobject role="fo">
          <imagedata fileref="velum_cpi.png" width="100%"/>
         </imageobject>
         <imageobject role="html">
          <imagedata fileref="velum_cpi.png" width="100%"/>
         </imageobject>
        </mediaobject>
       </informalfigure>
       <variablelist>
        <varlistentry>
         <term>Keystone API URL</term>
         <listitem>
          <para>
           Specifies the URL of the Keystone API used to authenticate the user.
           This value can be found in Horizon (the &ostack; control panel) under
           <guimenu>Project &rarr; Access and Security &rarr; API Access &rarr;
            Credentials</guimenu>.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Domain name</term>
         <listitem>
          <para>
           (Optional) Used to specify the name of the domain your user belongs
           to.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Domain ID</term>
         <listitem>
          <para>
           (Optional) Used to specify the name of the domain your user belongs
           to.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Project name</term>
         <listitem>
          <para>
           (Optional) Used to specify the name of the project where you want
           to create your resources.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Project ID</term>
         <listitem>
          <para>
           (Optional) Used to specify the name of the project where you want
           to create your resources.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Region name</term>
         <listitem>
          <para>
           Used to specify the identifier of the region to use when running on
           a multi-region &ostack; cloud. A region is a general division of
           an &ostack; deployment.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Username</term>
         <listitem>
          <para>
           Refers to the username of a valid user set in Keystone.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Password</term>
         <listitem>
          <para>
           Refers to the password of a valid user set in Keystone.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Subnet UUID for CaaS Platform private network</term>
         <listitem>
          <para>
           Used to specify the identifier of the subnet you want to create
           your load balancer on. This value can be found on the &ostack;
           control panels, under <guimenu>Project &rarr; Network &rarr;
           Networks</guimenu>. Click on the respective network to see its
           subnets.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Floating network UUID</term>
         <listitem>
          <para>
           (Optional) When specified, will lead to the creation of a floating
           IP for the load balancer.
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Load balancer monitor max retries</term>
         <listitem>
          <para>
           Number of permissible ping failures before changing the load
           balancer member's status to <literal>INACTIVE</literal>. Must be a
           number between 1 and 10. (Default: <replaceable>3</replaceable>)
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Cinder Block Storage API version</term>
         <listitem>
          <para>
           Specifies the API version to be used when talking to Cinder.
           Currently: <literal>v2</literal>
          </para>
         </listitem>
        </varlistentry>
        <varlistentry>
         <term>Ignore Cinder availability zone</term>
         <listitem>
          <para>
           Influence availability zone use when attaching Cinder volumes. When
           Nova and Cinder have different availability zones, this should be
           set to <literal>True</literal>.
          </para>
         </listitem>
        </varlistentry>
       </variablelist>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>Container runtime</term>
      <listitem>
       <warning>
        <para>
         Please note CRI-O is currently only a tech preview. It will work but
         is not officially supported.
        </para>
       </warning>
       <para>
        Allows choice between Docker and CRI-O as the main container runtime.
       </para>
      </listitem>
     </varlistentry>
     <varlistentry>
      <term>System wide certificate</term>
      <listitem>
       <para>
        Specify a system wide trusted certificate.
       </para>
      </listitem>
     </varlistentry>
    </variablelist>
   </step>
   <step>
    <para>
     Click <guimenu>Next</guimenu>.
    </para>
   </step>
   <step>
    <para>
     You will be shown an information screen about &ay;.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="velum_setup2.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="velum_setup2.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
    <para>
     This is now the time for you to install the master/worker nodes for
     the cluster.
    </para>
    <para>
     Continue with <xref linkend="sec-deploy-nodes-worker-install"/>.
    </para>
   </step>
  </procedure>
 </sect1>

 <sect1 xml:id="sec-deploy-nodes-worker-install">
  <title>Installing Master and Worker Nodes</title>
  <warning>
   <para>
    Before you can install the &worker_node;s of your new cluster, you need to
    install and configure the &admin_node;. Ensure that you have completed
    the steps in <xref linkend="sec-deploy-nodes-admin-install"/> and
    <xref linkend="sec-deploy-nodes-admin-configuration"/>.
   </para>
  </warning>

  <sect2 xml:id="sec-deploy-nodes-openstack">
   <title>Installation on Cloud services</title>
   <para>
    If you are installing on an &ostack; based cloud using HEAT templates or
    using a public cloud service (Azure, EC2, GCE), your machines will be set up
    automatically.
   </para>
   <important>
    <title>Adjust Salt Worker Threads For More Than 40 Nodes</title>
    <para>
     If you are deploying a cluster with more than <literal>40</literal> overall
     nodes, you must adjust the number of available Salt worker threads before
     you continue.
    </para>
    <para>
     Refer to:
     <xref linkend="sec-deploy-requirements-system-cluster-salt-cluster-size"/>.
    </para>
   </important>
   <para>
    You can continue directly to <xref linkend="sec-deploy-install-bootstrap"/>.
   </para>
  </sect2>

  <sect2 xml:id="sec-deploy-nodes-worker-install-manual">
   <title>Manual Installation</title>
   <procedure xml:id="pro-deploy-nodes-worker-install-manual">
    <step>
     <para>
      Follow the same procedure as for installing the &admin_node; in
      <xref linkend="sec-deploy-nodes-admin-install"/>, up
      until selection of the <guimenu>System Role</guimenu>.
     </para>
    </step>
    <step>
     <para>
      Select <literal>Cluster Node</literal> as <guimenu>System
      Role</guimenu> and enter the host name or IP address of the
      &admin_node;.
     </para>
     <note>
      <title>Plain System</title>
      <para>
       It is also possible to select a third node type, "plain node". These
       can be used for testing and debugging purposes, but are not usually
       needed.
      </para>
     </note>
    </step>
    <step>
     <para>
      After you have finalized the system configuration on the
      <guimenu>Installation Overview</guimenu> screen, click
      <guimenu>Install</guimenu>. Up to this point no changes have been made
      to your system. After you click <guimenu>Install</guimenu> a second
      time, the installation process starts.
     </para>
     <para>
      After a reboot, the new node should appear in the dashboard and can be
      added to your cluster.
     </para>
     <para>
      Repeat this procedure at least twice more to add a minimum of three
      nodes: one &master_node; and two &worker_node;s. This is the minimum
      supported size for a &productname; cluster.
     </para>
    </step>
    <step>
     <para>
      Once you have installed all desired machines, continue with
      <xref linkend="sec-deploy-install-bootstrap"/>.
     </para>
     <important>
      <title>Adjust Salt Worker Threads For More Than 40 Nodes</title>
      <para>
       If you are deploying a cluster with more than <literal>40</literal>
       overall nodes, you must adjust the number of available Salt worker
       threads before you continue.
      </para>
      <para>
       Refer to:
       <xref linkend="sec-deploy-requirements-system-cluster-salt-cluster-size"/>.
      </para>
     </important>
    </step>
   </procedure>
  </sect2>

  <sect2 xml:id="sec-deploy-nodes-worker-install-manual-autoyast">
   <title>Automatic Installation Using &ay;</title>
   <para>
    Before installing &worker_node;s with &ay;, you need to obtain the URL
    that points to the &ay; file on the &admin_node;. Generally, this will be
    supplied by the &dashboard; dashboard on the &admin_node;.
   </para>
   <note>
    <title>Using a modified &ay; control file</title>
    <para>
     You can customize various aspects of your installation by modifying the
     default &ay; control file. Refer to: <xref linkend="sec-deploy-autoyast" />.
    </para>
   </note>
   <note>
    <title>&rootuser; Password</title>
    <para>
     When nodes are installed using &ay;, there is no opportunity to specify
     the password for &rootuser;. However, each node will have <command>ssh</command>
     keys for &rootuser; on the &admin_node; pre-installed. Thus it is
     possible to access the &worker_node;s by opening an <command>ssh</command>
     session from the &admin_node;.
    </para>
   </note>
   <procedure xml:id="pro-deploy-nodes-worker-install-manual-autoyast">
    <step>
     <para>
      Insert the &productname; DVD into the drive, then reboot the computer
      to start the installation program.
     </para>
    </step>
    <step>
     <informalfigure>
      <mediaobject>
       <imageobject role="fo">
        <imagedata fileref="install_boot_ay.png" width="100%"/>
       </imageobject>
       <imageobject role="html">
        <imagedata fileref="install_boot_ay.png" width="100%"/>
       </imageobject>
      </mediaobject>
     </informalfigure>
     <para>
      Select <guimenu>Installation</guimenu> on the boot screen, but
      <emphasis>do not</emphasis> press <keycap function="enter"/>.
     </para>
     <para>
      Before proceeding to boot the machine, you should enter the necessary
      <guimenu>Boot Options</guimenu> for &ay; and networking.
     </para>
     <para>
      The most important options are:
     </para>
     <variablelist>
      <varlistentry>
       <term>autoyast</term>
       <listitem>
        <para>
         Path to the &ay; file. It is in the form of a URL built from the
         FQDN of the &admin_node;, followed the path to the &ay; file. For
         example, <literal>http://caasp-admin.example.com/autoyast</literal>
        </para>
        <para>
         If you are using a customized &ay; control file, you must substitute the
         default address from the &productname; cluster with the webserver URL
         that you are hosting the modified control file on.
        </para>
        <para>
         For more information, refer to
         <link xlink:href="https://www.suse.com/documentation/sles-12/book_autoyast/data/invoking_autoinst.html#commandline_ay"/>.
        </para>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>ifcfg</term>
       <listitem>
        <para>
         Network configuration. If you are using DHCP, you can simply enter
         <literal>ifcfg=eth0=dhcp</literal>. Make sure to replace
         <literal>eth0</literal> with the actual name of the interface that you
         want to use DHCP for. For manual configuration, refer to
         <link xlink:href="https://www.suse.com/documentation/sles-12/book_autoyast/data/ay_adv_network.html"/>.
        </para>
        <para>
         If you wish to define a static IP you can also use <command>ifcfg</command>.
         For example:
        </para>
<screen>
autoyast=http://admin.example.com/autoyast ifcfg=eth0=192.168.100.11/24,192.168.100.1,192.168.100.2,example.com hostname=master1.example.com
</screen>
       </listitem>
      </varlistentry>
      <varlistentry>
       <term>hostname</term>
       <listitem>
        <para>
         The host name for the node, if not provided by DHCP. If you manually
         specify a host name, make sure that it is unique.
        </para>
       </listitem>
      </varlistentry>
     </variablelist>
     <para>
      Press <keycap function="enter"/>. This boots the system and loads the
      &productname; installer.
     </para>
    </step>
    <step>
     <para>
      So long as there are no errors, the rest of the installation should
      complete automatically. After a reboot, the new  node should appear in
      the dashboard and can be added to your cluster.
     </para>
    </step>
    <step>
     <para>
      Once you have installed all desired machines, continue with
      <xref linkend="sec-deploy-install-bootstrap"/>.
     </para>
     <important>
      <title>Adjust Salt Worker Threads For More Than 40 Nodes</title>
      <para>
       If you are deploying a cluster with more than <literal>40</literal>
       overall nodes, you must adjust the number of available Salt worker
       threads before you continue.
      </para>
      <para>
       Refer to: <xref linkend="sec-deploy-requirements-system-cluster-salt-cluster-size"/>.
      </para>
     </important>
    </step>
   </procedure>
  </sect2>
 </sect1>

 <sect1 xml:id="sec-deploy-install-bootstrap">
  <title>Bootstrapping the Cluster</title>
  <para>
   To complete the installation of your &productname; cluster, it is necessary
   to bootstrap at least three additional nodes; those will be the &kube;
   master and workers.
<!-- cwickert 2017-07-23: FIXME We are already past AutoYaST -->
<!-- This process leverages &ay; and is (almost) fully automated. -->
  </para>
  <para>
   In case of problems, refer to <xref
   linkend="sec-admin-troubleshooting-failed-bootstrap" />.
  </para>
  <procedure xml:id="pro-deploy-install-bootstrap">
   <step>
    <para>
     Return to your admin node; with the &ay; instructions screen open from before.
    </para>
   </step>
   <step>
    <para>
     Click <guimenu>Next</guimenu>.
    </para>
   </step>
   <step>
    <para>
     On the screen <guimenu>Select nodes and roles</guimenu>, you will see a
     list of <literal>salt-minion</literal> IDs under <guimenu>Pending Nodes</guimenu>.
     These are internal IDs for the master/worker nodes you have just set up and
     which have automatically registered with the admin node in the background.
    </para>
   </step>
    <step>
    <para>
     <guimenu>Accept</guimenu> individual nodes into the cluster or click
     <guimenu>Accept All Nodes</guimenu>.
    </para>
   </step>
   <step>
    <para>
     Assign the roles of the added nodes.
    </para>
    <para>
     By clicking on <guimenu>Select remaining nodes</guimenu>, all
     nodes without a selected role will be assigned the <literal>Worker</literal>
     role.
    </para>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="velum_setup3.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="velum_setup3.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
    <important>
     <title>Minimum cluster size</title>
     <para>
      You must designate at least <literal>1</literal> master node and
      <literal>2</literal> worker nodes..
     </para>
    </important>
    <tip>
     <title>Assign Unused Nodes Later</title>
    <para>
     Nodes that you do not wish to designate for a role now, can later be
     assigned one on the &dashboard; status page.
    </para>
   </tip>
   </step>
   <step>
    <para>
     Once you have assigned all desired nodes a role, click
     <guimenu>Next</guimenu>.
    </para>
   </step>
    <step>
     <para>
      The last step is to configure the external FQDNs for dashboard and &kube;
      API.
     </para>
     <para>
      These values will determine where the nodes in the cluster will attempt
      to communicate.
     </para>
     <note>
      <title>Master Node Loadbalancer FQDN</title>
      <para>
        If you are planning a larger cluster with multiple &master_node;s,
        they must all be accessible from a single host name. If not, the
        functionality of &dashboard; will degrade if the original
        &master_node; is removed.
       </para>
       <para>
        Therefore, you should ensure that there is some form of load-balancing
        or reverse proxy configured at the location you enter here.
      </para>
     </note>
    <informalfigure>
     <mediaobject>
      <imageobject role="fo">
       <imagedata fileref="velum_setup4.png" width="100%"/>
      </imageobject>
      <imageobject role="html">
       <imagedata fileref="velum_setup4.png" width="100%"/>
      </imageobject>
     </mediaobject>
    </informalfigure>
    <variablelist>
    <varlistentry>
     <term>External Kubernetes API FQDN</term>
     <listitem>
      <para>
       Name used to reach the node running the &kube; API server.
      </para>
      <para>
       In a simple deployment with a single master node, this will be the name
       of the node that was selected as the &master_node; during bootstrapping
       of the cluster.
      </para>
    </listitem>
    </varlistentry>
    <varlistentry>
     <term>External Dashboard FQDN</term>
     <listitem>
      <para>
       Name used to reach the admin node running &dashboard;.
      </para>
    </listitem>
    </varlistentry>
   </variablelist>
   </step>
   <step>
    <para>
    Click on <guimenu>Bootstrap cluster</guimenu> to finalize the intial setup
    and start the bootstrapping process.
   </para>
   <para>
    The status overview will be shown while the nodes are bootstrapped for their
    respective roles in the background.
   </para>
   </step>
  </procedure>
 </sect1>

 <sect1 xml:id="sec-deploy-install-vmware-tools">
  <title>Installing &vmware; Tools</title>
  <para>
   This section is only relevant for deployments on &vmware; ESX and
   ESXi environments. This step is not required if you are using
   virtual disk images as described in <xref
   linkend="sec-deploy-preparation-disk-images" />, because
   <package>open-vm-tools</package> is already installed.
  </para>
  <para>
   After the bootstrapping of the cluster is finished, install the
   &vmware; tools on all nodes that are included in the package
   <package>open-vm-tools</package>. Log in on the &admin_node; and
   execute:
  </para>
  <procedure>
   <step>
    <para>
     Install <package>open-vm-tools</package> on all nodes.
    </para>
<screen>&prompt.root.admin;<command>docker exec $(docker ps -q --filter name=salt-master) \
salt -P "roles:admin|kube-master|kube-minion" \
cmd.run 'transactional-update pkg install --no-confirm open-vm-tools'</command></screen>
   </step>
   <step>
    <para>
     Reboot all nodes using <literal>salt</literal>. If you are already running
     a workload, also see <xref linkend="sec-admin-nodes-graceful-shutdown" />.
    </para>
<screen>&prompt.root.admin;<command>docker exec -it $(docker ps -q --filter name=salt-master) salt '*' system.reboot</command></screen>
   </step>
   <step>
    <para>
     Check status of &vmware; Tools in the ESX / ESXi user interface.
    </para>
   </step>
  </procedure>
 </sect1>
</chapter>
