<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE preface
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<!-- Converted by suse-upgrade version 1.1 -->
<chapter version="5.0" xml:id="cha.quick.requirements"
 xmlns="http://docbook.org/ns/docbook"
 xmlns:xi="http://www.w3.org/2001/XInclude"
 xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker></dm:bugtracker>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
  <title>&productname; System Requirements</title>
 </info>

 <para>
  Before you begin the installation, please make sure your system meets all the
  requirements listed below.
 </para>
 <sect1 xml:id="sec.quick.requirements.cluster">
  <title>Cluster Size Requirements</title>
  <para>
   &productname; is a dedicated cluster operating system and only functions in a
   multi-node configuration. It requires a connected group of four or more
   physical or virtual machines.
  </para>
  <para>
   The minimum supported cluster size is four nodes: a single &admin_node;, one
   &master_node;, and two &worker_node;s.
  </para>
  <note>
   <title>Test and Proof-of-Concept Clusters</title>
   <para>
    It is possible to provision a three-node cluster with only a single
    &worker_node;, but this is not a supported configuration for deployment.
   </para>
  </note>
  <para>
   For improved performance, multiple &master_node;s are supported, but there
   must always be an odd number. For cluster reliability, when using multiple
   master nodes, some form of DNS load-balancing should be used.
  </para>
  <para>Any number of &worker_node;s may be added up to the maximum cluster
   size. For the current maximum supported number of nodes, please refer to
   the Release Notes at <link xlink:href="https://www.suse.com/releasenotes/x86_64/SUSE-CAASP/3.0/"/>.
  </para>
 </sect1>

 <sect1 xml:id="sec.quick.requirements.hardware">
  <title>Minimum Node Specification</title>
  <para>
   Each node in the cluster must meet the following minimum specifications. All
   these specifications must be adjusted according to the expected load and type
   of deployments.
  </para>
  <variablelist>
   <varlistentry>
    <term>(v)CPU</term>
    <listitem>
     <itemizedlist>
      <listitem>
       <para>
        <literal>4 Core</literal> AMD64/Intel* EM64T processor
       </para>
      </listitem>
      <listitem>
       <para>
        32-bit processors are not supported
       </para>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Memory</term>
    <listitem>
     <itemizedlist>
      <listitem>
       <para>
        <literal>8 GB</literal>
       </para>
       <para>
        Although it may be possible to install &productname; with less memory
        than recommended, there is a high risk that the operating system will
        run out of memory and subsequently causes a cluster failure.
       </para>
       <note>
        <title>Swap partitions</title>
        <para>
         &kube; does not support swap.
        </para>
        <para>
         For technical reasons, an &admin_node; installed from an ISO image will
          have a small swap partition which will be disabled after installation.
          Nodes built using &ay; do not have a swap partition.
        </para>
       </note>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Storage Size</term>
    <listitem>
     <itemizedlist>
      <listitem>
       <para>
        <literal>40 GB</literal>
        for the root file system with Btrfs and enabled snapshots.
       </para>
       <note>
        <title>Cloud default root volume size</title>
        <para>
         In some Public Cloud frameworks the default root volume size of the
         images is smaller than 40GB. You must resize the root volume before
         instance launch using the command line tools or the web interface for
         the framework of your choice.
        </para>
       </note>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
   <varlistentry>
    <term>Storage Performance</term>
    <listitem>
     <itemizedlist>
      <listitem>
       <para>
        IOPS: <literal>500</literal> sequential IOPS
       </para>
      </listitem>
      <listitem>
       <para>
        Write Performance: <literal>10MB/s</literal>
       </para>
       <note>
        <title>etcd Storage requirements</title>
        <para>
         Storage performance requirements are tied closely to the
         <link xlink:href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/hardware.md#disks">etcd hardware recommendations</link>
        </para>
       </note>
      </listitem>
     </itemizedlist>
    </listitem>
   </varlistentry>
  </variablelist>
 </sect1>

 <sect1 xml:id="sec.quick.requirements.network">
  <title>Network Requirements</title>

  <itemizedlist mark="bullet" spacing="normal">
   <listitem>
    <para>
     All the nodes on the cluster must be on a the same network and be able to
     communicate directly with one another.
    </para>
    <important>
     <title>Reliable Networking</title>
     <para>
      Please make sure all nodes can communicate without interruptions.
     </para>
    </important>
   </listitem>
   <listitem>
    <para>
     All nodes in the cluster must be assigned static IP addresses. Using
     dynamically assigned IPs will break cluster functionality after
     update/reboot.
    </para>
   </listitem>
   <listitem>
    <para>
     The admin node and the &kube; API master must have valid Fully-Qualified
     Domain Names (FQDNs), which can be resolved both by all other nodes and
     from other networks which need to access the cluster.
    </para>
    <para>
     Admin node and &kube; API master node should be configured as CNAME records
     in the local DNS. This improves portability for disaster recovery.
    </para>
   </listitem>
   <listitem>
    <para>
     A DNS server to resolve host names. If you are using host names to
     specify nodes, please make sure you have reliable DNS resolution at all
     times, especially in combination with DHCP.
    </para>
    <important>
     <title>Unique Host Names</title>
     <para>
      Host names must be unique. It is recommended to let the DHCP server
      provide not only IP addresses but also host names of the cluster nodes.
     </para>
    </important>
   </listitem>
   <listitem>
    <para>
     On the same network, a separate computer with a Web browser is required
     in order to complete bootstrap of the cluster.
    </para>
   </listitem>
   <listitem>
    <para>
     We recommend that &productname; is setup to run in two subnets in
     one network segment, also referred to as VPC or VNET. The
     &admin_node; should run in a subnet that is not accessible to the
     outside world and should be connected to your network via VPN or
     other means. Consider a security group/firewall that only allows
     ingress traffic on ports 22 (SSH) and 443 (https) for the
     Administrative node from outside the VPC. All nodes must have
     access to the Internet through some route in order to connect to
     &scc; and receive updates, or be otherwise configured to receive
     updates, for example through &smt;.
    </para>
    <para>
     Depending on the applications running in your cluster you may
     consider exposing the subnet for the cluster nodes to the outside
     world. Use a security group/firewall that only allows incoming
     traffic on ports served by your workload. For example, a
     containerized application providing the backend for REST based
     services with content served over https should only allow ingress
     traffic on port 443.
    </para>
   </listitem>
  </itemizedlist>

  <important>
   <title>Unique Host Names</title>
   <para>
    All nodes' host names must be unique. If two or more nodes have the same
    host name, bootstrap of the cluster will fail.
   </para>
  </important>

  <note>
   <title>Clusters without Fully-Qualified Domain Names</title>
   <para>
    For test purposes, IP addresses can be substituted for the FQDNs for the
    &admin_node; and &master_node;, but this is not supported for production
    deployment.
   </para>
  </note>

 </sect1>
 <sect1 xml:id="sec.quick.requirements.limits">
  <title>Limitations</title>
  <itemizedlist mark="bullet" spacing="normal">
<!-- cwickert 2017-09-18: Caas 1 supports up to 25 nodes, CaaS 2 up to 50,
       see https://bugzilla.suse.com/show_bug.cgi?id=1055049
       FIXME: Check again for CaaS 3.
    <para>
     &productname; &productnumber; supports up to 50 nodes per cluster.
    </para>
   </listitem>
   <listitem>
-->
<!-- cwickert 2017-04-06: FIXME - check if still applies
       https://bugzilla.suse.com/show_bug.cgi?id=1029317
       jahalackova: that's still valid for 1.0.
       lproven 2018-03-27: and for 3
-->
   <listitem>
    <para>
     &productname; &productnumber; does not support remote installations with
     Virtual Network Computing (VNC).
    </para>
   </listitem>
   <listitem>
    <para>
     &productname; is a dedicated cluster-node operating system. Dual-booting
     with other operating systems is not supported. It must be the only
     operating system installed on each node.
    </para>
   </listitem>
  </itemizedlist>
 </sect1>
</chapter>
