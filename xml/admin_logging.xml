<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter
[
  <!ENTITY % entities SYSTEM "entity-decl.ent">
    %entities;
]>
<chapter version="5.1" xml:id="cha.admin.logging"
  xmlns="http://docbook.org/ns/docbook"
  xmlns:xi="http://www.w3.org/2001/XInclude"
  xmlns:xlink="http://www.w3.org/1999/xlink">
 <info>
  <title>Logging</title>
  <dm:docmanager xmlns:dm="urn:x-suse:ns:docmanager">
   <dm:bugtracker/>
   <dm:translation>yes</dm:translation>
  </dm:docmanager>
 </info>

 <important>
  <title>Scope Of This Document</title>
  <para>
   The scope of this document is limited to the &productname; Infrastructure
   layer.
  </para>
  <para>
   For information on how to access log files for the individual
   components, please refer to the respective official documentation of the
   component.
  </para>
 </important>

 <sect1 xml:id="sec.admin.logging.intro">
  <title>About &productname; Logging</title>
  <para>
   Logging across the cluster is done on multiple logical levels. You can think
   of them as three logical layers (simplified).
  </para>

   <itemizedlist>
    <listitem>
     <para>
      &productname; Infrastructure (Salt, Velum, LDAP)
     </para>
    </listitem>
    <listitem>
     <para>
      Cluster (etcd, dex, tiller, kubernetes apiserver, kubernetes controller-manager, kubernetes scheduler)
    </para>
   </listitem>
   <listitem>
    <para>
     Pod (kubelet, haproxy, flanneld, systemd, journald, dmesg)
    </para>
   </listitem>
  </itemizedlist>

  <para>
   The individual log files allow introspection of activities across the cluster.
   Due to some technical limitations it is sometimes not possible to directly
   trace log events from one layer to the next. Most log files would be used for
   debugging purposes only.
  </para>
 </sect1>

 <sect1 xml:id="sec.admin.logging.admin">
  <title>Admin Node Logs</title>
  <para>
   More information to be added.
  </para>

  <sect2 xml:id="sec.admin.logging.velum">
   <title>&dashboard; Logs</title>
   <para>
    More information to be added.
   </para>
  </sect2>

  <sect2 xml:id="sec.admin.logging.ldap">
   <title>LDAP Logs</title>
   <para>
    &productname; &dashboard; uses OpenLDAP.
   </para>
   <para>
    More information to be added.
   </para>
  </sect2>
 </sect1>

 <sect1 xml:id="sec.admin.logging.salt">
  <title>Salt Logging</title>
  <para>
   <literal>Salt</literal> performs a variety of functions that control behavior
   and configuration of the &kube; cluster. A failure of executing certain
   <literal>Salt</literal> workflows could lead to an unhealthy cluster, in such
   a case it can be inspected using <literal>Salt</literal> log information".
  </para>

  <sect2 xml:id="sec.admin.logging.salt.orchestration">
   <title>Salt Orchestration Log</title>
   <para>
    The <literal>Salt</literal> orchestration logs contains log entries about
    orchestration events that have changed the cluster.
   </para>
   <para>
    Orchestration events are
   </para>
   <itemizedlist>
    <listitem>
     <para>
      Bootstrapping
     </para>
    </listitem>
    <listitem>
     <para>
      Adding new nodes
     </para>
    </listitem>
    <listitem>
     <para>
      Removing nodes
     </para>
    </listitem>
    <listitem>
     <para>
      Updating settings
     </para>
    </listitem>
    <listitem>
     <para>
      Upgrading a cluster
     </para>
    </listitem>
   </itemizedlist>

<screen>&prompt.user;<command>/var/lib/supportutils-plugin-suse-caasp/debug-salt \
--json_output=events.txt \
--summary_output=events-summarized.txt \
--text-status \
--no-color</command>
         </screen>

   <para>
    Reading the <filename>events-summarized.txt</filename> file
    should be enough for detecting most (if not all) of the issues caused by
    <literal>Salt</literal>.
   </para>
  </sect2>

  <sect2 xml:id="sec.admin.logging.salt.master">
   <title>Salt Master Log</title>
   <para>
    Retrieve the <literal>Salt master</literal> logs. These logs don't include
    any information to trace past or ongoing actions; but rather errors that
    have been raised by the <literal>Salt master</literal> itself.
   </para>

<screen>&prompt.user;<command>docker exec -it $(docker ps | grep salt-master | awk '{print $1}') \
cat /var/log/salt/master</command>
    </screen>

  </sect2>

  <sect2 xml:id="sec.admin.logging.salt.minion">
   <title>Salt Minion Logs</title>
   <para>
    Retrieve the <literal>salt-minion</literal> logs for all nodes. This will
    show all output for all <literal>salt-minions</literal> at once. Execute the
    following command on the admin node.
   </para>
   <para>
    Of course, it's possible to retrieve this information on any specific node
    by reading the <filename>/var/log/salt/minion</filename> file.
   </para>
<screen>
&prompt.user;<command>docker exec -it $(docker ps | grep salt-master | awk '{print $1}') \
salt '*' cmd.run "cat /var/log/salt/minion"</command>
    </screen>

  </sect2>
 </sect1>

 <sect1 xml:id="sec.admin.logging.transactional-updates">
  <title>Transactional Update Log</title>
  <para>
   The <command>transactional-update</command> method processes updates in the
   background and generates new machine image snapshots. This process can run
   into issues. Possible causes are connectivity issues or timeouts against the
   package repository. In such cases the update fails and the affected node will
   be marked with a red cross in &dashboard;.
  </para>
  <para>
   In most cases this situation resolves itself the next time the update process
   runs automatically. If you have performed manual updates or must debug a
   failed update, you can read the log for <command>transactional-update</command>
   with the command below.
  </para>

  <para>
   For more information, see: <xref linkend="sec.admin.software.transactional-updates"/>
  </para>

<screen>
&prompt.user;<command>docker exec -it $(docker ps | grep salt-master | awk '{print $1}') \
salt -P 'roles:(admin|kube-master|kube-minion)' \
cmd.run "journalctl -u transactional-update"</command>
 </screen>
 </sect1>

 <sect1 xml:id="sec.admin.logging.audit">
  <title>&kube; Audit Log</title>
  <para>
   To track actions that have been performed on the cluster, you can enable the
   &kube; audit log in &dashboard;.
  </para>
  <para>
<<<<<<< Updated upstream
   Navigate to: <guimenu>Settings &rarr; KUBERNETES &rarr; Auditing</guimenu>.
   This allows the audit logs to be written on the &kube; master nodes at
   <filename>/var/log/kube-apiserver/audit.log</filename> and you can then use
   an external data collector like <literal>fluentd</literal> to collect all the
   audit logs.
=======
   There's a notable exception at infra level, and is that we allow audit logs
   to be configured from within Velum. This allows the audit logs to be written
   on the &kube; master nodes at <filename>/var/log/kube-apiserver/audit.log</filename>
   and an external data collector like <literal>fluentd</literal>
   can be used to collect all the audit logs.
>>>>>>> Stashed changes
  </para>

  <note>
   <title>Kubernetes Audit Log Documentation</title>
   <para>
    For more information on the audit log and its contents, see:
    <link xlink:href="https://v1-9.docs.kubernetes.io/docs/tasks/debug-application-cluster/audit/">Kubernetes Documentation: Auditing</link>
   </para>
  </note>

  <important>
   <title>&kube; Audit Log Limitations</title>
   <para>
    The &kube; audit log only collects and stores actions performed on the &kube;
    level of the cluster. This does not include any actions performed by
    &productname; administrators in &dashboard; or any of the resulting
    actions of services.
   </para>
  </important>

  <informalfigure>
   <mediaobject>
    <imageobject role="fo">
     <imagedata fileref="velum_settings_audit.png" width="100%" format="png"/>
    </imageobject>
    <imageobject role="html">
     <imagedata fileref="velum_settings_audit.png" width="100%" format="png"/>
    </imageobject>
   </mediaobject>
  </informalfigure>

  <variablelist>
   <varlistentry>
    <term>Enable Auditing</term>
    <listitem>
    <para>
     Enable / Disable the audit logging feature (Default: <literal>Disabled</literal>)
    </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Max size</term>
    <listitem>
    <para>
     Maximum size in megabytes of the audit log file before it gets rotated
     (Default: <literal>10</literal>)
    </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Max age</term>
    <listitem>
    <para>
     Maximum number of days to retain old audit log files (Default: <literal>15</literal>)
    </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Max backup</term>
    <listitem>
    <para>
     Maximum number of audit log files to retain (Default: <literal>20</literal>)
    </para>
   </listitem>
   </varlistentry>
   <varlistentry>
    <term>Policy</term>
    <listitem>
    <para>
     The YAML file defining the <link xlink:href="https://v1-9.docs.kubernetes.io/docs/tasks/debug-application-cluster/audit/#audit-policy">auditing policy rules</link>
    </para>
   </listitem>
   </varlistentry>
  </variablelist>
 </sect1>

 <sect1 xml:id="sec.admin.logging.fluentd">
  <title>External log collection (fluentd)</title>


  <para>
   At &kube; level, there are different solutions that can be implemented, for example: <literal>fluentd</literal>
   can be used to collect all applications log in a central instance (https://docs.fluentd.org/v0.12/articles/kubernetes-fluentd).
   Then, Elasticsearch and Kibana can be used (https://kubernetes.io/docs/tasks/debug-application-cluster/logging-elasticsearch-kibana/)
   to have an intuitive way to interact with the logs.

   https://docs.fluentd.org/v0.12/articles/kubernetes-fluentd
  </para>
 </sect1>

 <sect1 xml:id="sec.admin.logging.log-levels">
  <title>Log levels</title>
  <para>
   There are two main components and their respective sub-components that
   allow configuration of different loglevels: Salt and &kube;.
  </para>

  <itemizedlist>

   <listitem>
    <para>
     Salt
    </para>
     <itemizedlist>
      <listitem>
       <para>
        Salt master
       </para>
       </listitem>
       <listitem>
        <para>
         Salt minion on each machine
        </para>
       </listitem>
      </itemizedlist>
    </listitem>

    <listitem>
     <para>
      &kube;
     </para>
     <itemizedlist>
      <listitem>
       <para>
        Master nodes
       </para>
       <itemizedlist mark="circle">
        <listitem>
         <para>
          apiserver
         </para>
        </listitem>
        <listitem>
         <para>
          controller-manager
         </para>
        </listitem>
        <listitem>
         <para>
          scheduler
         </para>
        </listitem>
       </itemizedlist>
      </listitem>

      <listitem>
       <para>
        All nodes
       </para>
       <itemizedlist mark="circle">
        <listitem>
         <para>
          kubelet
         </para>
        </listitem>
        <listitem>
         <para>
          kube proxy
         </para>
        </listitem>
        </itemizedlist>
      </listitem>
     </itemizedlist>
    </listitem>
  </itemizedlist>

  <sect2 xml:id="sec.admin.logging.log-levels.salt">
   <title>Salt Log Levels</title>

   <para>
    Salt provides different loglevels that apply both to the master and the
    minions.
   </para>

   <itemizedlist>
    <listitem>
     <para>
      all
     </para>
    </listitem>
    <listitem>
     <para>
      garbage
     </para>
    </listitem>
    <listitem>
     <para>
      trace
     </para>
    </listitem>
    <listitem>
     <para>
      debug
     </para>
    </listitem>
    <listitem>
     <para>
      profile
     </para>
    </listitem>
    <listitem>
     <para>
      info
     </para>
    </listitem>
    <listitem>
     <para>
      warning
     </para>
    </listitem>
    <listitem>
     <para>
      error
     </para>
    </listitem>
    <listitem>
     <para>
      critical
     </para>
    </listitem>
    <listitem>
     <para>
      quiet
     </para>
    </listitem>
   </itemizedlist>

   <para>
   For detailed explanations of the usage of these log levels please see:
   <link xlink:href="https://docs.saltstack.com/en/latest/ref/configuration/logging/">Salt Log Levels (Upstream)</link>
   </para>

   <sect3 xml:id="sec.admin.logging.log-levels.salt.debug">
    <title>Setting a different log level</title>
    <para>
    When debugging issues, <literal>debug</literal> is usually enough and is
    what the &productname; engineers use to debug problems.
    </para>

    <sect4 xml:id="sec.admin.logging.log-levels.salt.debug.master">
     <title>Salt Master</title>

    <para>
     In the case of the <literal>salt-master</literal>, this configuration can be
     modified in the admin node, at <filename>/etc/caasp/salt-master-custom.conf</filename>.
     Inside this file you can add: <literal>log_level: debug</literal>.
    </para>

    <para>
     Note that after any change on this file you need to restart the
     <literal>salt-master</literal> container, like:
    </para>
<screen>
<command>docker rm -f $(docker ps | grep salt-master | awk '{print $1}')</command>.
     </screen>

    <para>
     After deleting this container, the <literal>kubelet</literal> will bring a
     new <literal>salt-master</literal> container automatically with the new
     configuration applied. So you can check the logs with the
     <literal>debug</literal> loglevel.
     </para>

<screen>
<command>docker logs -f $(docker ps | grep salt-master | awk '{print $1}')</command>
   </screen>
  </sect4>

  <sect4 xml:id="sec.admin.logging.log-levels.salt.debug.minion">
   <title>Salt Minions</title>
   <note>
    <title>Modifications on Salt minions are not persistent</title>
    <para>
     These changes are discarded when the node is updated with a new snapshot by
     <literal>transactional-update</literal>.
    </para>
  </note>
   <para>
    In the case of the <literal>Salt</literal> minions, there's no "official"
    way to tweak this configuration, however, a new file can be added on the
    minion that you want to print debugging <literal>Salt</literal> information
    in: <filename>/etc/salt/minion.d/100-debug.conf</filename>. After doing a
    <command>systemctl restart salt-minion</command> you can check that it now
    prints debugging information with <command>journalctl -fu salt-minion</command>.
   </para>

  </sect4>
  </sect3>
  </sect2>

  <sect2 xml:id="sec.admin.logging.log-levels.kubernetes">
   <title>&kube; Log Levels</title>
   <para>
    For &kube; our default <literal>loglevel</literal> is <literal>2</literal>
    <link xlink:href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/#kubectl-output-verbosity-and-debugging">Kubernetes Upstream: Output Verbosity and Debugging</link>.
    However, this setting can be tweaked by using pillar overrides. If modified,
    this setting will be applied to all &kube; components; there's no way to set
    a different loglevel per components. Moreover, there is no way to specify
    different loglevels per machine.
   </para>
  </sect2>

 </sect1>
</chapter>
